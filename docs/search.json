[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Understanding Statistics Through Linear Models",
    "section": "",
    "text": "Motivation\nStatistics is a word that rhymes with sadistics. Many people have noted this similarity and have felt that sadistics is what was really meant. Admittedly, statistics is hard, even statisticians find it hard. So why on earth would we want to do it? The main reason is because we want to be able to trust in our results as objectively as possible and applying some statistics can help us to do that.\nFor reasons beyond their control, during their education a lot of biologists with a molecular or biochemistry or genetics or field background develop only a vague conceptual framework about statistics, one that leaves them with the idea that it is all about picking the right test and then they’re ok. Often they have gone through a graduate course that introduced them to a lot of tests and a lot of conditions that must be fulfilled and they have gained the impression that there is one ‘right’ test to use in any given situation, which isn’t true. Later on this misapprehension is reinforced by the good intentions of colleagues and reviewers with apparently eidetic memories that seem to remember all the conditions and can suggest the ‘right’ test to them in lab meetings or during manuscript revision. Many don’t get an experience where there is a sense of working through a statistical problem logically or a discussion of ways of thinking about the problem.\nAs a result, many of us get the sense that everything to do with statistics is arbitrary and dislocated without any logical binding thread. If your prior experience has left you feeling that statistics is a bit of an incomprehensible mess, then this course is for you.\nThe aim of this course is to introduce a simple new tool and a way of thinking about statistics that can enlighten and simplify all the tests we commonly use as biologists. It may surprise you that this tool will be based on a simple formula for a straight line, something you probably already know. We will look at the bare bones of this and see how it relates to significance tests and see how by thinking of straight lines in your work then you can apply complicated analyses quickly and importantly come to a clearer understanding of the hypotheses you are testing.\nHappy sadistics statistics!",
    "crumbs": [
      "Motivation"
    ]
  },
  {
    "objectID": "01-background.html",
    "href": "01-background.html",
    "title": "1  The essence of statistics",
    "section": "",
    "text": "1.1 Null Models\nWe all know that doing the same experiment twice will return different results each time. Perhaps not massively different, but definitely not exactly the same. Variation like this can make it hard for us to assert that there are differences between the things we are testing. This is the central issue that statistics seeks to address, in plain English we ask\nthe answer to this in statistics is usually the same one - compare it to the situation where there isn’t any difference, if it is an unlikely result there, then perhaps there is a difference. This ‘situation where there isn’t any difference’ is called a Null Model, or perhaps you can think of it as a random model or a default model.\nAnd that’s the whole of the logic to a statistical test - we simply make an assumption about what a Null Model of no difference is, then use it to see how likely a given difference would be in that model.\nA Null Model will always have some way of incorporating variability, if you ask for a likelihood of a given difference, there will always be an effect of variability on the likelihood, usually the as variability increases the likelihood that there is a difference decreases.\nEither way, for our purposes the basic idea is that we look inside the null model and see how likely it would be. Usually we ask a very specific question of a Null Model\nThe likelihood of the difference under the Null Model is expressed as a very misunderstood and abused quantity - the \\(p\\)-value.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The essence of statistics</span>"
    ]
  },
  {
    "objectID": "01-background.html#null-models",
    "href": "01-background.html#null-models",
    "title": "1  The essence of statistics",
    "section": "",
    "text": "How can I be reasonably certain that the difference I see is a real one?\n\n\n\n\n\n\n\n\n\nSkinning Cats\n\n\n\nJust because the overall answer is usually the same one, that doesn’t mean that there is only one way of generating a Null Model. Far from it! The selection of the Null Model is one of the thorniest issues in statistics and is one of the reasons most often cited for selecting one type of test over another. Often the Null Model will be the Normal Distribution, which you may have heard of (and yes, it’s called the Normal because it’s the one we normally use) other common ones are the Binomial or Poisson, the exponential, the Gamma and the \\(t\\) and \\(\\chi-squared\\). Thankfully, the tool we are going to learn will be able to use all of these appropriately. For most of this book our focus will be on Normal Null Models.\n\n\n\n\n\nWhat is the likelihood of getting the difference we observed if the true difference were 0, given the observed amount of variablility?",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The essence of statistics</span>"
    ]
  },
  {
    "objectID": "01-background.html#p-values",
    "href": "01-background.html#p-values",
    "title": "1  The essence of statistics",
    "section": "1.2 \\(p\\)-values",
    "text": "1.2 \\(p\\)-values\nA lot of researchers get the impression that \\(t\\)-tests, ANOVAs and other hypothesis tests tell you whether something is significant with probability \\(p\\). This is quite a misinterpretation. They do no such thing. More accurately but still rather informally and in general \\(p\\) can be taken as follows\n\n\n\n\n\n\nWhat \\(p\\) really is\n\n\n\n\\(p\\) should be thought of as the frequency of seeing a difference of the size observed in the Null Model\n\n\nRemembering that the Null Model is the default situation where the difference is 0 then this is resolutely not the same as saying they are definitely different. Just that they’re not likely to be the same. The \\(p\\) in \\(p\\) value is usually taken to mean ‘probability’, but if it stands for anything it should be ‘probably not the same’.\nHypothesis testing like this has been criticized for being weak inference, and not without reason. All this means is that we need to be awake to the limitations of our methods.\nWith this idea of using a Null Model as a reference to see whether our difference is likely or not we can start to think about defining a difference.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The essence of statistics</span>"
    ]
  },
  {
    "objectID": "01-background.html#slopes-of-straight-lines-can-help-us-think-about-differences-between-things",
    "href": "01-background.html#slopes-of-straight-lines-can-help-us-think-about-differences-between-things",
    "title": "1  The essence of statistics",
    "section": "1.3 Slopes of straight lines can help us think about differences between things",
    "text": "1.3 Slopes of straight lines can help us think about differences between things\nOne way of examining a difference is to think about the slopes of straight lines. It isn’t immediately obvious how this works, intuitively we might just want to think about numbers, so let’s work through a quick example. Let’s consider these data\n\nlibrary(itssl)\ndf &lt;- its_bardata_time()\nits_table_time(df)\n\n\n\n\ngroup1\ngroup2\n\n\n\n\n6.357027\n6.650224\n\n\n4.217032\n5.343997\n\n\n4.011094\n6.603704\n\n\n6.459490\n6.046695\n\n\n4.163264\n5.420880\n\n\n6.614712\n7.056854\n\n\n\n\n\nIn the beginning of our scientific education we might’ve plotted them as barcharts, by taking the mean, like this.\n\nits_barplot_time(df)\n\n\n\n\n\n\n\n\nImagine drawing a line between the tops of the bars, like this:\n\nits_barplot_time(df, join_tops = TRUE)\n\n\n\n\n\n\n\n\nThe slope of that line tells us about the difference in the means. If it is flat there’s no difference, if it isn’t flat maybe there is a difference.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow we have a conceptual tool for thinking about differences (like differences in means of samples) as a slope between the means from one group to another. And that is the logic we will be following in this little book. All we will do is learn to look for a slope of a line. We’ll look at using a statistical tool called a linear model, which tries to create a straight line that matches the data, so it contains the equation of a straight line but elaborates on the equation alone by providing measures of believability about the slope and other things. The technique we will learn will give us a framework for thinking about performing hypothesis testing in all sorts of comparisons including \\(t\\)-tests, ANOVA, etc. and with elaborations we’ll be able to see how to use the same framework for the other class of tests that we often use, the non-parametric tests.\n\n\n\n\n\n\nRoundup\n\n\n\n\nWe do statistics to be reasonably certain that differences we observe don’t occur by chance.\nA \\(p\\) value doesn’t tell us the probability of a result. It tells us how often we would see the observed result in an idealised and simplisitic situation.\nThe slope of a line can help us think about whether two numbers are different.\n\n\n\n\n\n\n\n\n\nFor you to do\n\n\n\nComplete the interactive quiz online https://tsl-bioinformatics.shinyapps.io/linear_models_background/",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>The essence of statistics</span>"
    ]
  },
  {
    "objectID": "02-linear-models.html",
    "href": "02-linear-models.html",
    "title": "2  The linear model",
    "section": "",
    "text": "2.1 From straight lines to data\nNow that we’ve decided to use the straight line as our Null Model, with a flat line being the case where there is no difference and a sloped line being otherwise, we need to start to think about lines and a statistical relative called a Linear Models. Linear models are a tool that are similar to a line of best fit, with measures of the variability of the data points that go in to building them. The linear model will be how we bring statistical rigour into our conceptual tool of using straight lines to think about differences. In this section we’ll look at them in some detail, but first we’ll recap some facts about straight lines.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The linear model</span>"
    ]
  },
  {
    "objectID": "02-linear-models.html#straight-line-relationships-are-described-using-two-parameters",
    "href": "02-linear-models.html#straight-line-relationships-are-described-using-two-parameters",
    "title": "2  The linear model",
    "section": "2.2 Straight line relationships are described using two parameters",
    "text": "2.2 Straight line relationships are described using two parameters\nIts all about \\(y = ax + b\\) (or \\(y = mx + c\\), depending on where you went to school). These two equivalent formulae are the standard high-school equations for describing a straight line. They represent how the quantity \\(y\\) changes as \\(x\\) does.\nAs a refresher, \\(a\\) tells us how much \\(y\\) increases for every unit increase in \\(x\\). Here’s an example for the equation \\(y = 4x\\)\n\nlibrary(itssl)\nits_axplusb_time(a = 4)\n\n\n\n\n\n\n\n\nIf we play about with that value, the slope of the line changes, the \\(a\\) term is known as the slope, or gradient, or more often because it is just a multiplier of \\(x\\) its called the coefficient. Here’s some different coefficients just to prove that point\n\nits_axplusb_time(a = 4) +\n  its_add_line_time(a = 2, colour = \"deepskyblue\") +\n  its_add_line_time(a = 6, colour = \"darkorange\")\n\n\n\n\n\n\n\n\nThe \\(b\\) part of the formula just tells us how much we add on to \\(y\\) after we’ve calculated the coefficient effect. It has the effect of pushing the line up and down the y-axis. When we look at the value of \\(y\\) for \\(x = 0\\) we get the position that the graph hits the y-axis so this number is often called the intercept. Here’s a set of lines to show that.\n\nits_axplusb_time(a = 4, b = 0) + \n  its_add_line_time(a = 4, b = -2, colour = \"deepskyblue\") +\n  its_add_line_time(a = 4, b = 2, colour = \"darkorange\")\n\n\n\n\n\n\n\n\nThat’s all we need to know about the equation of the straight line. Now we need to look at how they’re a useful tool when analysing experimental data.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The linear model</span>"
    ]
  },
  {
    "objectID": "02-linear-models.html#linear-models-try-to-create-a-linear-equation-from-data",
    "href": "02-linear-models.html#linear-models-try-to-create-a-linear-equation-from-data",
    "title": "2  The linear model",
    "section": "2.3 Linear models try to create a linear equation from data",
    "text": "2.3 Linear models try to create a linear equation from data\nA linear model is a simplification of the relationship between some sets of numbers (in the simple case we will introduce here, it is two sets, but it can be more). At its heart is a straight line, with the equation we discussed above and a certain set of values for \\(a\\) (the coefficient) and \\(b\\) the intercept, along with some statistics that describe the strength of the relationship.\nLet’s walk through building one, graphically and in R.\nFirst we need some sets of values, \\(x\\) and \\(y\\). Usually, these would be from an experiment, but here I’ll make some toy ones.\n\ndf &lt;- its_random_xy_time(20)\nits_plot_xy_time(df)\n\n\n\n\n\n\n\n\nThe graph shows 20 random \\(x\\) values between 5 and 15 plotted against 20 \\(y\\) values which are calculated as \\(2x\\) with a little random noise added. We can see that there is definitely a relationship (not least because we engineered it that way). The objective of the linear model is to quantify and describe the relationship in some way and here’s where the linear equation comes in. If we could come up with a line that fitted through the data we could use the equation of that line to roughly describe - or model - our data. Skipping to the end a bit, then there is absolutely a way to get the line from the data. The methods are described in lots of statistics books so I won’t repeat them, but you may be familiar with the general methods, it’s the ‘line of best fit’ according to the ordinary least squares method. Details aside, the actual linear model function we need in R is lm() and it works like this\n\nlm(y ~ x, data = df)\n\nThat’s it! The function lm() does the work, it takes a fairly odd syntax, though. The y ~ x bit is an R formula and describes the relationship you want to examine, you can read it as y depends on x. The y and x we’re referring to here are the two columns of numbers we created and plotted above, the data argument just says in which object to look for the data.\nLooking at the function output we get this\n\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nCoefficients:\n(Intercept)            x  \n      0.778        1.955  \n\n\nThese are the intercept (\\(b\\)) and the coefficient of \\(x\\) (\\(a\\)) that we need to describe the line. So our data are described by the line \\(y = 1.955x + 0.778\\).\nSo this line is a model of the data, it’s a model in the sense that it is something that represents our data, but isn’t it. Looking at them together we can see the model and the data it stands for.\n\nits_plot_xy_time(df, line = TRUE)\n\n\n\n\n\n\n\n\nThe line alone can be useful to teach us about our data, but there’s more to the linear model than just the line.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The linear model</span>"
    ]
  },
  {
    "objectID": "02-linear-models.html#linear-models-describe-relationships-between-variables",
    "href": "02-linear-models.html#linear-models-describe-relationships-between-variables",
    "title": "2  The linear model",
    "section": "2.4 Linear models describe relationships between variables",
    "text": "2.4 Linear models describe relationships between variables\nBeyond working out the equation of the line, the linear model process aims to quantify and describe relationships between the variables in the data, in our toy example the variables are \\(x\\) and \\(y\\). Specifically when we say ‘relationship’, we mean whether a change in the value of \\(x\\) appears to go along with some change in the value of \\(y\\).\nIn other words, we can think of relationship as being the slope. If \\(x\\) causes some change in \\(y\\) when we plot it then there must be a slope. We call the slope \\(a\\) in our equation of a line and we call it the coefficient of the \\(x\\) term in our linear model. These are all equivalent interpretations for our purposes, slope, relationship, coefficient.\nLinear models calculate statistics to help us decide whether the coefficient/slope/\\(a\\) of the relationship we observe is important or not.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The linear model</span>"
    ]
  },
  {
    "objectID": "02-linear-models.html#not-all-lines-of-best-fit-are-equally-good",
    "href": "02-linear-models.html#not-all-lines-of-best-fit-are-equally-good",
    "title": "2  The linear model",
    "section": "2.5 Not all lines of best fit are equally good",
    "text": "2.5 Not all lines of best fit are equally good\nAlthough a line of best fit can always be calculated, the line might not be worth much. Consider two sets of very similar numbers. Here’s two vectors of random numbers with the same mean and their plot.\n\nmore_df &lt;- data.frame(\n  x &lt;- runif(20, 5, 15),\n  y &lt;- runif(20, 5, 15)\n)\n\nits_plot_xy_time(more_df)\n\n\n\n\n\n\n\n\nWe can definitely calculate a line that fits these,\n\nlm(y ~ x, data = more_df)\n\n\nCall:\nlm(formula = y ~ x, data = more_df)\n\nCoefficients:\n(Intercept)            x  \n    10.4695       0.1103  \n\n\nand it would be \\(y = 0.1103x + 10.6495\\). But if we compare the fit of those lines, like in these plots\n\n\n\n\n\n\n\n\n\n\n\n\n\nwe can clearly see that not all lines are created equal. The first line fits the data much more closely than the second one. We can also see that the relationship between \\(x\\) and \\(y\\) is much weaker in the second set than in the first (the coefficient/slope/\\(a\\) is weaker. So a sensible linear model of our data would give us not just the equation but also measures of the closeness of fit and therefore believability of the value of slope of the line. In terms of our Null Model flat line/sloped line model this means that when we have a significant coefficient, we are not likely to have a flat line. Let’s look at the statistics in the linear model that show us what a significant coefficient is.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The linear model</span>"
    ]
  },
  {
    "objectID": "02-linear-models.html#linear-models-contain-statistics-describing-the-goodness-of-the-model",
    "href": "02-linear-models.html#linear-models-contain-statistics-describing-the-goodness-of-the-model",
    "title": "2  The linear model",
    "section": "2.6 Linear models contain statistics describing the goodness of the model",
    "text": "2.6 Linear models contain statistics describing the goodness of the model\nThe same function we’ve already used - lm() - calculates certain statistics. We can print them using the summary() function.\n\nmodel &lt;- lm(y ~ x, data = df)\nsummary(model)\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.17560 -1.00570 -0.01092  1.17016  1.83047 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.7780     1.1442    0.68    0.505    \nx             1.9555     0.1122   17.42 1.03e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.303 on 18 degrees of freedom\nMultiple R-squared:  0.944, Adjusted R-squared:  0.9409 \nF-statistic: 303.6 on 1 and 18 DF,  p-value: 1.027e-12\n\n\nThis output is verbose, there are four blocks.\n\nModel Call - just a restatement of the function we called\nResiduals - a set of measures of the distribution of the residuals, we’ll look at this later.\nCoefficients - the terms of the equation and their statistics; so the intercept (\\(b\\)) and the coefficient of x (\\(a\\)) that we’ve already seen and the Estimate (computed values of those). We see also columns of statistics for each.\nThe model level statistics summary - some statistics that apply to the whole model.\n\nLet’s start at the bottom and look at model level summary.\n\n2.6.1 Residual Standard Error\nThis is a measure of how well the line fits the data. In essence Residual Standard Error is the average distance from each real data point to the line, the further the points are from the line (the worse the fit) the bigger the Residual Standard Error. If you look at the plots again with those distances drawn in you can see quite clearly the residual error for the second model is much bigger than for the first.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe error term\n\n\n\nWe’re working hard here to avoid using too much mathematical notation and examination of the mechanics of the linear model, but the residuals are quite an important aspect, so Im going to use this aside to delve just a little deeper. Unlike the linear equation, the linear model has an extra error term, \\(e\\) which represents the residuals by quantifying the average distance from the actual measurments to the line in the y-axis.\nThe \\(e\\) term adds something onto the y value of the whole equation; the bigger \\(e\\) is the more we need to add on to the value of the \\(x\\) from the line to get the real \\(y\\). Logically, the bigger \\(e\\) is the more the line misses the points in the model overall. The error is a major determinent of whether a model is any good or whether things are significant so it’s worth knowing how it relates to the model.\n\n\n\n\n2.6.2 \\(R^2\\)\n\\(R^2\\) is another measure of how well the model fits the data. If you’re thinking correlation coefficient here, then you’re in the right area. \\(R^2\\) describes the proportion of variance in the \\(y\\) values that can be explained by the \\(x\\) values. The \\(R^2\\) always falls between 0 and 1. Closer to 1 is usually better, but it is very domain and dataset dependent. With small and biological data sets, we don’t always see values close to 1 because of the noise of the system.\nThe proper one to use in most all cases is the Adjusted R-squared.\n\n2.6.2.1 \\(R^2\\) versus Residual Standard Error\nSo what’s the difference between these two - at first glance they do the same thing. The major difference is that RSE is in the units of the data and \\(R^2\\) is in relative units, so you can use them in different situations e.g if you want to make your model work within particular tolerances or you want to compare models in different units.\n\n\n\n2.6.3 \\(F\\)-Statistic\nThe \\(F\\)-Statistic is an indicator of a relationship between the \\(x\\) and \\(y\\) values of the model. In effect \\(F\\) tests how much better the relationship is in your model than a model in which the relationship is completely random. It’s actually a ratio such that when the \\(F\\)-statistic is at 1, the relationship is no stronger than a random relationship. The further above 1 \\(F\\) is, the more it is likely there is a real relationship in the model. The \\(p\\) value here is the \\(p\\) that this size of \\(F\\) would occur in a random relationship with a similar dataset size. As with the other statistics, the significance of the actual size of \\(F\\) is dependent on the domain and data being analysed.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The linear model</span>"
    ]
  },
  {
    "objectID": "02-linear-models.html#coefficients-have-statistics",
    "href": "02-linear-models.html#coefficients-have-statistics",
    "title": "2  The linear model",
    "section": "2.7 Coefficients have statistics",
    "text": "2.7 Coefficients have statistics\nAlong with these model level statistics, linear modelling with lm() gives us a set of statistics per coefficient. These measure the effect that each coefficient has on the output variable \\(y\\). Basically a significant coefficient, is one that has a non-zero slope and is an important determinant of the value of \\(y\\).\n\n2.7.1 Estimate\nThese are the Estimate, which is the actual value of the coefficient from the model. We will see that along with Intercept we can have models with more than one other coefficient. These are given in the units of the data.\n\n\n2.7.2 Std. Error\nA measure of the variability of the strength of the effect, so if some \\(x\\) points give more pronounced \\(y\\) values at similar coefficient values, you get a higher variability of the strength. Generally lower standard error of the coefficient is good.\n\n\n2.7.3 \\(t\\)-value\nAn estimate of how extreme the coefficient value is, basically how many Standard Deviations away the estimated coefficient is from the centre of a presumed Normal distribution with mean 0. It is absolutely a \\(t\\)-test \\(t\\)-value, and like in a \\(t\\)-test we want it to be high. The higher \\(t\\) is, then the more likely that the coefficient is not 0.\n\n\n\n\n\n\nWait, what?\n\n\n\nWhy would we care whether the coefficient is 0 or not? Well, because if it is 0, then it’s having no effect on the model. Consider again the equation of a line\n\\[\\begin{equation}\ny = ax + b\n\\end{equation}\\]\nIf we let the coefficient \\(a = 0\\), this happens\n\\[\\begin{equation}\ny = 0 x + b\\\\\ny = b\n\\end{equation}\\]\nThe coefficient disappears, it’s having no effect!\nIf the coefficient is not many standard deviations away from 0, it’s probably not having much effect on the relationship. The \\(t\\) value tries to work out whether, given the data, the coefficient is in anyway different to 0.\nIn plainer English, we are really saying that the size if the slope is not likely to be 0. That it is not likely that there is no relationship. Which is weak inference, but is exactly the same sort of inference that all the other hypothesis tests make and is exactly the same interpretation.\nOf course, this will depend on the size of the standard deviation. The noisier the data or the smaller the sample size then the larger this value will need to be to be important.\n\n\n\n\n2.7.4 \\(Pr(&gt;|t|)\\)\nThis weird shorthand expression is just giving the probability of getting a value larger than the \\(t\\)-value. This comes from a \\(t\\)-test within the model and takes into account the dataset size and variability, you can think of it as the \\(p\\)-value of a test asking whether the coefficient is equal to 0. So if \\(p\\) is less than 0.05 you can say that the value of the coefficient is not likely to be 0 and therefore is having an effect on the model.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The linear model</span>"
    ]
  },
  {
    "objectID": "02-linear-models.html#a-non-zero-slope-is-what-matters",
    "href": "02-linear-models.html#a-non-zero-slope-is-what-matters",
    "title": "2  The linear model",
    "section": "2.8 A non-zero slope is what matters",
    "text": "2.8 A non-zero slope is what matters\nBy looking at the \\(p\\)-value of the coefficient then, we can see whether there is a significant relationship or, more accurately a non-zero slope\nWe can really emphasise by looking at the plots of lines we looked at earlier.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe slope of the second plot is weaker, it’s much flatter - much closer to zero, in fact given the spread of the data we aren’t that confident that it isn’t a flat (zero) slope, so we aren’t that confident that there is a significant relationship.\nWe can quickly see that definitively using lm() if we compare two models based on those two datasets.\nWe already built the model for the first slope.\n\nsummary(model)\n\n\nCall:\nlm(formula = y ~ x, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.17560 -1.00570 -0.01092  1.17016  1.83047 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.7780     1.1442    0.68    0.505    \nx             1.9555     0.1122   17.42 1.03e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.303 on 18 degrees of freedom\nMultiple R-squared:  0.944, Adjusted R-squared:  0.9409 \nF-statistic: 303.6 on 1 and 18 DF,  p-value: 1.027e-12\n\n\nLet’s also build the model for the second slope, it is in a dataframe called more_df\n\nmodel_2 &lt;- lm(y ~ x, data = more_df)\nsummary(model_2)\n\n\nCall:\nlm(formula = y ~ x, data = more_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.1924 -1.5007  0.1171  1.7748  3.8260 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  10.4695     2.0315   5.154 6.67e-05 ***\nx             0.1103     0.2127   0.519     0.61    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.296 on 18 degrees of freedom\nMultiple R-squared:  0.01472,   Adjusted R-squared:  -0.04001 \nF-statistic: 0.269 on 1 and 18 DF,  p-value: 0.6103\n\n\nWe can clearly see that the second model is a poorer fit to the data. The model level statistics are less convincing: \\(F\\) is reduced to 0.269 (from 303.6), the \\(p-value\\) shows the difference occurs by chance 61 % of the time and the Adjusted R-squared is close to 0, indicating a poor relationship. The coefficient was measurable, but it is not significant (and not coincidentally) occurring by chance 61 % of the time. The slope therefore is not significantly different from 0 and \\(x\\) in model_2 appears to have no effect on \\(y\\).\nIt is this slope assessing feature of the linear models that will help us in our overall goal of using the linear model to do the work of all the other statistical tests we commonly use. If we have a good model and a good fit, then we can make really flexible use of the slope by looking at the significance of the coefficient.",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The linear model</span>"
    ]
  },
  {
    "objectID": "02-linear-models.html#major-points",
    "href": "02-linear-models.html#major-points",
    "title": "2  The linear model",
    "section": "2.9 Major points",
    "text": "2.9 Major points\nAfter all that inspection of the linear model, here’s what you need to remember:\n\n\n\n\n\n\nTake-homes\n\n\n\n\nLinear models describe relationships between sets of numbers (variables)\nThe creation of the model generates statistics about the goodness of the model\nA non-zero coefficient (slope) means there is not likely to be no relationship (!)",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The linear model</span>"
    ]
  },
  {
    "objectID": "02-linear-models.html#extra-credit-understanding-linear-models-through-the-notation",
    "href": "02-linear-models.html#extra-credit-understanding-linear-models-through-the-notation",
    "title": "2  The linear model",
    "section": "2.10 Extra credit: Understanding linear models through the notation",
    "text": "2.10 Extra credit: Understanding linear models through the notation\nIn this section at the end I wanted to take one last step and look at how the linear model is specified because the notation is an aid to understanding the model a bit more deeply. It’s probably OK to skip this bit if the idea of notation doesn’t grab you. At the start of this chapter we wrote the linear equation like this\n\\[\\begin{equation}\ny = ax + b\n\\end{equation}\\]\nand through the chapter we developed the idea that the linear model is the line with some statistics and noise built in, such that we can try to render it like this\n\\[\\begin{equation}\ny = ax + b + e\n\\end{equation}\\]\nwith \\(e\\) being a measure of error (or random measurement differences) added on, somehow, and it does aid our thinking to take that liberty a little, because of the way we can see the relationship of the error now.\nBut unlike a straight line, a linear model doesn’t have to have only one slope, it can have many. This doesn’t mean that the line has a bend in it, like this\n\nits_bendy_line_time()\n\n\n\n\n\n\n\n\nbut rather that the model can take into account more than one data axis (variable) (or dimension) - more like this, where a new variable is called \\(z\\), so the whole thing if plotted looks more like the top 3D panel here in which the model allows us to see the combined effects of \\(x\\) and \\(z\\) on the output \\(y\\) but we can focus on each variable individually by taking one at a time, like in the two split panels at the bottom (note how this is like looking into the front and right side of the 3D panel individually).\n\nits_three_variable_plot_time()\n\n\n\n\n\n\n\n\nWe can only see up to two extra axes in a plot, and only visualise three without getting twitchy eyes, but going to three, four or many more dimensions is no problem for the linear model framework and they all work the same way. When it comes to notating this we run into a problem as we run out of letters. Let’s build it up…\nFirst, a one slope/coefficient/independent variable model, adding one variable at a time\n\\[\\begin{equation}\ny = ax + e\n\\end{equation}\\]\nThe first thing that happens is the linear model disposes of the intercept term \\(b\\), that’s OK, it is still computed, but we don’t have it in the model notation now. Next we build up the number of variables/dimensions. We’ve already used \\(a\\) and \\(x\\) so for the next slope we can use \\(z\\) for the variable and \\(b\\) for its coefficient. We can go further for a third slope and use \\(w\\) and \\(c\\)\n\\[\\begin{align*}\ny &= ax + bz + e\\\\\ny &= ax + bz + cw + e\n\\end{align*}\\]\nHold on though, this is already getting very confusing, \\(cw\\) is a bit hard to follow and it only gets worse. To get around this proliferation the notation of a linear model usually uses subscript numbers, all coefficients are given the Greek letter beta \\(\\beta\\), all variables are given \\(x\\) and each is written with a little number after that distinguishes them\n\\[\\begin{equation}\ny = \\beta_1 x_1 + e\n\\end{equation}\\]\nthen that can be extended easily to \\(n\\) sets of variables. Finally, because the relationship between \\(y\\) and the variables in a linear model isn’t strictly speaking a mathematical equality we use the ~ operator.\n\\[\\begin{equation}\ny \\sim \\beta_1 x_1 + \\beta_2 x_2 \\dotsc + \\beta_n x_n + e\n\\end{equation}\\]\nWe can see from this equation that a linear model is really just a load of variables added together to give some outcome \\(y\\). This makes much more sense when we put words in. Let’s consider a plant growth experiment, in which we varied light, water and fertilizer and measured weight. The model in words looks like this\n\\[\\begin{equation}\n\\mbox{weight} \\sim \\beta_1 \\mbox{light} + \\beta_2 \\mbox{water} + \\beta_3 \\mbox{fertilizer} + e\n\\end{equation}\\]\nWe can see that what the linear model is looking for is all those values of \\(\\beta\\) - it is going to calculate slopes for us. It is the job of the linear model to work out the coefficients and intercepts from the data we put into it and to tell us which of the slopes are non-zero ones and therefore important in determining the size of the output variable. With this information we can tell not only significant differences between the variables, but whether any are more important than others in affecting the outcome.\nAt the very least knowing notation like this will be useful later when we are looking at comparing multiple variables with linear models, but the linear model also gives us a lot of ways of talking about our experiment that we might not otherwise have had. The model gives us a way of assessing and quantifying the effects of the experimental variables on the outcome and a way of making quantitative predictions or hypotheses about the experiment, we can use expected values of the coefficients to say how we believe a model will work, when it proves to be different from the data we can validate or falsify our hypotheses.\n\n\n\n\n\n\nRoundup\n\n\n\n\nStraight lines are described by an equation with two parameters\nLinear models contain information about the data and can tell us whether a slope is likely flat or not given the data\n\n\n\n\n\n\n\n\n\nFor you to do\n\n\n\nComplete the interactive quiz online https://tsl-bioinformatics.shinyapps.io/linear_models/",
    "crumbs": [
      "Background",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>The linear model</span>"
    ]
  },
  {
    "objectID": "03-ttest.html",
    "href": "03-ttest.html",
    "title": "3  \\(t\\)-tests and linear models",
    "section": "",
    "text": "3.1 Recap\nIn this section we’ll look at how the linear model can be used as a conceptual tool to understand the sort of comparison a \\(t\\)-test does and as a straightforward way to perform a hypothesis test.\nBecause I like hammering this point home, Im going to recap two important points from our earlier work on linear models.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$t$-tests and linear models</span>"
    ]
  },
  {
    "objectID": "03-ttest.html#recap",
    "href": "03-ttest.html#recap",
    "title": "3  \\(t\\)-tests and linear models",
    "section": "",
    "text": "The slope of the model is the important thing\n‘Significance’ tests only test whether the difference between two things is ‘probably not 0’\n\n\n3.1.1 The slope of the model again\nRecall the simplified linear model equation we developed\n\\[\\begin{equation}\ny = ax + b\n\\end{equation}\\]\nand that if we let the coefficient \\(a = 0\\), the effect of \\(x\\) disappears\n\\[\\begin{equation}\ny = 0 x + b\\\\\ny = b\n\\end{equation}\\]\nSo the logical conclusion is that if we have a coefficient that is non-zero, we have a relationship/effect of \\(x\\) on \\(y\\).\nIt is this property that lets us use the linear model to work out whether there is a significant difference between groups. That is to say we can use it as a \\(t\\)-test!",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$t$-tests and linear models</span>"
    ]
  },
  {
    "objectID": "03-ttest.html#using-two-different-samples-instead-of-a-continuous-x-variable",
    "href": "03-ttest.html#using-two-different-samples-instead-of-a-continuous-x-variable",
    "title": "3  \\(t\\)-tests and linear models",
    "section": "3.2 Using two different samples instead of a continuous \\(x\\) variable",
    "text": "3.2 Using two different samples instead of a continuous \\(x\\) variable\nThe second we try to apply what we’ve learned with the linear model to a two-sample dataset we hit an apparent problem because we’ve learned how to make linear models from datasets with a continuous, numeric \\(x\\)-axis, but the data we have for a \\(t\\)-test has a very different two category look, something like these here:\nlibrary(itssl)\n\ncontinuous_x &lt;- its_random_xy_time(20)\nits_plot_xy_time(continuous_x)\ncategoric_x &lt;- its_bardata_time()\nits_barplot_time(categoric_x)\n\n\n\n\n\n\n\n\n\n\nRest assured, the problem isn’t insurmountable. We need to do a couple of numeric tricks to get this to work like the continuous data, and they’re fairly easy, so let’s run through them,\nThe first step is to realise that although we are used to thinking of the each of the bars representing a single number, that single number is (almost always) a summary, like a mean of replicate values, so let’s go back to those source numbers as a first step and plot those, here are some examples\n\n\n\n\n\ngroup1\ngroup2\n\n\n\n\n4.895422\n6.849330\n\n\n5.225740\n6.257527\n\n\n4.828976\n6.703222\n\n\n5.878021\n6.593268\n\n\n4.068426\n7.895864\n\n\n4.985580\n7.542633\n\n\n\n\n\n\n\n\n\n\n\n\nplotting gives us something a lot more like the scatter plot we need for the model as we’ve been thinking about it, but it isn’t quite clear how the categorical \\(x\\) becomes numeric. To do this we simply select a number for each group, so our data will look like this\n\nlibrary(dplyr)\nlong_x &lt;- its_wide_to_long_time(categoric_x) %&gt;% \n  mutate(x = if_else(group == \"group1\",0,1))\n\nits_table_time(long_x)\n\n\n\n\ngroup\nvalue\nx\n\n\n\n\ngroup1\n4.895422\n0\n\n\ngroup2\n6.849330\n1\n\n\ngroup1\n5.225740\n0\n\n\ngroup2\n6.257527\n1\n\n\ngroup1\n4.828976\n0\n\n\ngroup2\n6.703222\n1\n\n\ngroup1\n5.878021\n0\n\n\ngroup2\n6.593268\n1\n\n\ngroup1\n4.068426\n0\n\n\ngroup2\n7.895864\n1\n\n\ngroup1\n4.985580\n0\n\n\ngroup2\n7.542633\n1\n\n\n\n\n\nSo now we can make a plot with two numeric axes, that looks a lot more like the one we’re expecting for our model\n\nlibrary(ggplot2)\n  ggplot(long_x) + aes(x, value) + geom_point() + theme_minimal() \n\n\n\n\n\n\n\n\nalbeit with the \\(x\\)-values in two places on the \\(x\\)-axis - its enough for us to make a slope on the line between the two groups and that means that we can use the linear model for the categoric data, as we did for the continuous.\nIf this seems like a bit of a ‘hack’ then I’d agree. However, this is part of the numeric bookkeeping that we often have to do in statistics. Its not wrong and ‘hacks’ are usually just pragmatic and useful solutions to problems, this one is completely mathematically legitimate as well as useful.\nAnd if this change in the data reminds you of tidy data we’ve used in other courses, like dplyr, then that is no accident. Tidy data is designed to make this sort of analysis easy to work through, at least as far as organising the data goes.\nThe good news is that once we have our data set up with a category and value column, the lm() function just deals with assigning the numbers for us, we don’t have to worry, the problem of continuous or categoric \\(x\\)-axes just disappears! All you need to know is that under the hood the linear model uses numbers for categories instead of words to make things easy.\nNow that we understand how we can use categoric data in a linear model, let’s get to the point of this chapter and work through an example of a linear model based hypothesis test for differences between two groups that functions as a \\(t\\)-test.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$t$-tests and linear models</span>"
    ]
  },
  {
    "objectID": "03-ttest.html#the-plantgrowth-data",
    "href": "03-ttest.html#the-plantgrowth-data",
    "title": "3  \\(t\\)-tests and linear models",
    "section": "3.3 The PlantGrowth data",
    "text": "3.3 The PlantGrowth data\nR comes with lots of datasets built in. One if these is PlantGrowth, which describes the dry weight of plants in grams in replicated measurements in a control and two treatments. We can load it with data() and get a summary()\n\ndata(\"PlantGrowth\")\nsummary(PlantGrowth)\n\n     weight       group   \n Min.   :3.590   ctrl:10  \n 1st Qu.:4.550   trt1:10  \n Median :5.155   trt2:10  \n Mean   :5.073            \n 3rd Qu.:5.530            \n Max.   :6.310            \n\nhead(PlantGrowth)\n\n  weight group\n1   4.17  ctrl\n2   5.58  ctrl\n3   5.18  ctrl\n4   6.11  ctrl\n5   4.50  ctrl\n6   4.61  ctrl\n\n\nWe have three groups and one measurement. The \\(x\\) values would come from the group column (and we now know that because it is categoric rather than continuous we needn’t worry, the model functions will just do the conversion for us). And of course the \\(y\\) values would come from the weight column.\nIn linear modelling jargon, the \\(x\\) values are called the independent or explanatory variable, simply because this is the one we changed over the course of the experiment. The \\(y\\) values are called the dependent or response variables as this is the one that responds or changes according to the changes in the independent variable.\nFor simplicity at this stage we’ll work with two groups only. Let’s remove trt2.\n\ntwo_groups &lt;- its_remove_a_group_time(PlantGrowth)\nsummary(two_groups)\n\n     weight       group   \n Min.   :3.590   ctrl:10  \n 1st Qu.:4.388   trt1:10  \n Median :4.750            \n Mean   :4.846            \n 3rd Qu.:5.218            \n Max.   :6.110            \n\n\nWith that done, we can look at the categorical scatter plot.\n\nlibrary(ggplot2)\np &lt;- ggplot(two_groups) + aes(group, weight) + geom_point()\np\n\n\n\n\n\n\n\n\nWe can clearly see the weight spread in each group. By eye we can see that the groups overlap in the \\(y\\)-axis (weight) quite considerably, though trt1 seems to have a couple of data points that are lower.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$t$-tests and linear models</span>"
    ]
  },
  {
    "objectID": "03-ttest.html#a-linear-model-with-a-categoric-x-axis",
    "href": "03-ttest.html#a-linear-model-with-a-categoric-x-axis",
    "title": "3  \\(t\\)-tests and linear models",
    "section": "3.4 A linear model with a categoric \\(x\\)-axis",
    "text": "3.4 A linear model with a categoric \\(x\\)-axis\nLet’s make the linear model and get the intercept and coefficient of the line. This can be done with lm() as we did before.\n\ntwo_groups_model &lt;- lm(weight ~ group, data = two_groups)\ntwo_groups_model\n\n\nCall:\nlm(formula = weight ~ group, data = two_groups)\n\nCoefficients:\n(Intercept)    grouptrt1  \n      5.032       -0.371  \n\n\nThat calculates easily! The lm() isn’t worried by the fact that one of our variables is categoric. It knows all the levels of the group variable and gives us the intercept and coefficient as it did before.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$t$-tests and linear models</span>"
    ]
  },
  {
    "objectID": "03-ttest.html#using-the-statistics-of-the-linear-model-to-test-for-differences",
    "href": "03-ttest.html#using-the-statistics-of-the-linear-model-to-test-for-differences",
    "title": "3  \\(t\\)-tests and linear models",
    "section": "3.5 Using the statistics of the linear model to test for differences",
    "text": "3.5 Using the statistics of the linear model to test for differences\nNow we have a categoric linear model built we can start to look at how to use it to check for differences between the groups.\n\nsummary(two_groups_model)\n\n\nCall:\nlm(formula = weight ~ group, data = two_groups)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0710 -0.4938  0.0685  0.2462  1.3690 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5.0320     0.2202  22.850 9.55e-15 ***\ngrouptrt1    -0.3710     0.3114  -1.191    0.249    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6964 on 18 degrees of freedom\nMultiple R-squared:  0.07308,   Adjusted R-squared:  0.02158 \nF-statistic: 1.419 on 1 and 18 DF,  p-value: 0.249\n\n\nFrom the output we can see the coefficient isn’t huge, only about 1/3 of a gram decrease as we change along the \\(x\\) axis by one unit. Saying change along the axis by one unit in categoric axes sounds a bit strange, but in the categoric data it just means switching from one group to the next. Recall that we put one group at 0 and the second at 1 when we were doing the numeric ‘hack’ above, the distance between the groups is defined as 1, so it all makes sense to say ’a change along the \\(x\\) by one unit. Lets add the line to the plot and have a look.\n\np + geom_abline(intercept = 5.03, slope = -0.371)\n\n\n\n\n\n\n\n\nJust looking at the plot makes the line seem more substantial than it is. Looking at the \\(y\\)-axis and the places where the line intercepts with the categories then we can see the difference is close to the coefficient.\n\n3.5.1 The coefficient and the mean difference between groups are equivalent\nBefore we move along with our model, we should look at that coefficient of the group variable a bit more. As we’re moving from the ctrl to treatment groups the coefficient tells us the size of the change. So does this mean that the coefficient is equivalent to other measures by which we can tell the difference in two groups - is it, for example equivalent to calculating the difference in the means of the groups? Short answer is yes! Let’s look at that, recalling that the coefficient is -0.371.\nFirst get the means of the groups using a little dplyr\n\nmean_two_groups &lt;- two_groups %&gt;% \n  group_by(group) %&gt;% \n  summarize(mean_wt = mean(weight))\n\nmean_two_groups\n\n# A tibble: 2 × 2\n  group mean_wt\n  &lt;fct&gt;   &lt;dbl&gt;\n1 ctrl     5.03\n2 trt1     4.66\n\n\nNow calculate the difference\n\n5.03 - 4.66\n\n[1] 0.37\n\n\nThere you have it, the absolute values of each are very similar. You can use the coefficient as a way of finding the difference between the groups. Another handy feature of the linear model.\n\n\n3.5.2 The \\(p\\)-value of the coefficient tests the same thing as a \\(t\\)-test\nWe already know that the \\(Pr(&gt;|t|)\\) value (\\(p\\)-value of the coefficient) tells us the probability that we would see the slope observed or greater in random samples if the real difference were 0. The two-sample \\(t\\)-test reports the probability that we would see the difference in means observed if the real difference were 0. So the two are very similar, the question is are they similar enough as a replacement?\nThe \\(p\\)-value for the coefficient in the linear model was 0.249. How does this compare with a \\(t\\)-test?\n\nt.test(weight ~ group, data = two_groups)\n\n\n    Welch Two Sample t-test\n\ndata:  weight by group\nt = 1.1913, df = 16.524, p-value = 0.2504\nalternative hypothesis: true difference in means between group ctrl and group trt1 is not equal to 0\n95 percent confidence interval:\n -0.2875162  1.0295162\nsample estimates:\nmean in group ctrl mean in group trt1 \n             5.032              4.661 \n\n\nIt is extremely close! In fact, as the sample size increases and gets over about 15 it gets to be exact. So this is useful, we can use the linear model slope and \\(p\\)-value as a mental and practical alternative for thinking about the more complicated to understand \\(t\\)-test. We can use the linear model instead of the \\(t\\)-test if we want to.\nAll you have to understand is that you are looking at the slope of the line between the groups. If you don’t see a slope of that size very often, then you can say its not likely that there’s no difference 1",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$t$-tests and linear models</span>"
    ]
  },
  {
    "objectID": "03-ttest.html#summary",
    "href": "03-ttest.html#summary",
    "title": "3  \\(t\\)-tests and linear models",
    "section": "3.6 Summary",
    "text": "3.6 Summary\nHopefully, this plot summarises how to look for differences between two groups using a linear model quite succinctly.\n\nThink of the line between the mean of the groups\nDoes the \\(p\\)-value tell you that you don’t see a slope of this size often in the assumed Null Model.\n\nSo you just need the coefficient and the \\(p\\)-value from the linear model. When we’re thinking of the coefficient of the linear model for differences we’re just asking something very similar to whether the line that joins the two means has a non-zero slope, given the error.\nIn a hypothesis test way, what we’re asking amounts to the following two hypotheses:\n\nA flat line with slope of zero is equivalent to the Null hypothesis\n\n\\(H_{0}\\) the group means are equal\n\nA \\(p\\)-value that suggests the slope is rare is equivalent to the Alternative hypothesis\n\n\\(H_{1}\\) the group means are not equal\n\n\nand it can be summarised verbally as in this diagram",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$t$-tests and linear models</span>"
    ]
  },
  {
    "objectID": "03-ttest.html#but-wasnt-the-t-test-just-easier",
    "href": "03-ttest.html#but-wasnt-the-t-test-just-easier",
    "title": "3  \\(t\\)-tests and linear models",
    "section": "3.7 But wasn’t the \\(t\\)-test just easier?",
    "text": "3.7 But wasn’t the \\(t\\)-test just easier?\nIn the sloped line / linear model process we’ve been learning we used the t.test() function to calculate the \\(p\\)-value that tested the hypothesis that the true difference in the means between groups was 0. This was pretty easy and we didn’t have to think too hard, we just got the result. Why wouldn’t we stick to just using that, especially if it’s equivalent to the linear model? There’s no definitive reason, the \\(t\\)-test is a perfectly good tool, and it’s a great one to use. Don’t feel like I’m telling you not to use the \\(t\\)-test.\nThe focus of this whole tutorial is to give you a way to think of statistical techniques that is generally useful. Because the linear model provides a general answer to all these sorts of questions - one small set of techniques is re-usable lots of times, so the idea goes that in lots of experiments the statistics become a lot easier to understand. I hope I’m not confusing the two intents. If you’ve followed the logic of the straight line and slope and the linear model and can use it to inform your \\(t\\)-test usage in the future, then we’re in good shape.\nThe general applicability of the straight line and linear model concept comes in handy when comparing more than two groups. Looking at effects in these experiments is basically the same thing as doing just two, though traditionally we’d use a seemingly very different sort of test - ANOVA. We’ll look at that in the next section.\n\n\n\n\n\n\nRoundup\n\n\n\n\nA linear model can be used as a \\(t\\)-test\nUsing the linear model rather than the \\(t\\)-test gives us a more consistent and flexible framework to think about differences between groups\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nComplete the interactive tutorial online https://tsl-bioinformatics.shinyapps.io/ttests/",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$t$-tests and linear models</span>"
    ]
  },
  {
    "objectID": "03-ttest.html#footnotes",
    "href": "03-ttest.html#footnotes",
    "title": "3  \\(t\\)-tests and linear models",
    "section": "",
    "text": "Again this is weak inference, but that’s this type of statistics for you!↩︎",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>$t$-tests and linear models</span>"
    ]
  },
  {
    "objectID": "04-anova.html",
    "href": "04-anova.html",
    "title": "4  ANOVA and linear models",
    "section": "",
    "text": "4.1 Comparing groups in a single variable\nIn the last section we looked at using the linear model to compare two groups, in this section we’ll look at using it to compare more than two. One thing to note is that (for now) we’re still working with only one explanatory variable (that is one thing we measured), the groups we are talking about are basically different values that the one variable can take. In the PlantGrowth data the variable is called group and the values it takes are ctrl, trt1 and trt2.\nYou’ll be pleased to know this is where the pay off comes. Any number of groups (and later any number of variables) is no more complicated than the two we’ve already done.\nWe can visualise the process as simply being a case where we have more than one line to examine. Consider this figure, here we draw the categorical scatter plot and draw lines joining all the different group means that indicate the different comparisons we might choose to do with these data.\nlibrary(itssl)\nits_multi_category_with_lines_time()\nSo we’ll need to know how to read the linear model for each of the given lines. Let’s jump in and work through that. First let’s build a linear model with a variable with multiple groups.\nmodel &lt;- lm(weight ~ group, data = PlantGrowth)\nsummary(model)\n\n\nCall:\nlm(formula = weight ~ group, data = PlantGrowth)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0710 -0.4180 -0.0060  0.2627  1.3690 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5.0320     0.1971  25.527   &lt;2e-16 ***\ngrouptrt1    -0.3710     0.2788  -1.331   0.1944    \ngrouptrt2     0.4940     0.2788   1.772   0.0877 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6234 on 27 degrees of freedom\nMultiple R-squared:  0.2641,    Adjusted R-squared:  0.2096 \nF-statistic: 4.846 on 2 and 27 DF,  p-value: 0.01591\nGreat! so we handle the extra levels of the variable nearly perfectly. There are two lines of coefficient results, the first showing the gradient between the ctrl and trt1 and the second showing the gradient between ctrl and trt2. The ctrl data has clearly been used as a common reference - this is the default design in the function, the first group in the data becomes the common reference. Here we get away with it, as we do want the first level to be the common reference. When you need to change the order, you can set the reference level explicitly.\ndf &lt;- PlantGrowth\ndf$group&lt;- relevel(df$group, ref=\"trt2\")\nmodel2 &lt;- lm(weight ~ group  , data = df,)\nsummary(model2)\n\n\nCall:\nlm(formula = weight ~ group, data = df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0710 -0.4180 -0.0060  0.2627  1.3690 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5.5260     0.1971  28.032  &lt; 2e-16 ***\ngroupctrl    -0.4940     0.2788  -1.772  0.08768 .  \ngrouptrt1    -0.8650     0.2788  -3.103  0.00446 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6234 on 27 degrees of freedom\nMultiple R-squared:  0.2641,    Adjusted R-squared:  0.2096 \nF-statistic: 4.846 on 2 and 27 DF,  p-value: 0.01591\nAnd now we see the trt2 as common reference against the ctrl and trt1 groups.\nIn these data only trt2 vs trt1 appears to be significant according to the linear model model2 but we did need to create two models to do this, which is a bit of a statistical mess. If this seems longwinded or illogical, then that’s fair. The two models have the same data and specification so should have the same results in - it was really just the way we were ordering things in the data that was different. The real problem is just one of bookkeeping.\nThe linear models are rich and not all the comparisons that can be done with them can easily be written in summary(model). To answer specific questions from an analysis technique for getting specific comparisons (or contrasts in the statistics jargon) from linear models has been invented, that technique is called ANOVA (Analysis of Variance).",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA and linear models</span>"
    ]
  },
  {
    "objectID": "04-anova.html#comparing-groups-in-a-single-variable",
    "href": "04-anova.html#comparing-groups-in-a-single-variable",
    "title": "4  ANOVA and linear models",
    "section": "",
    "text": "Tip\n\n\n\nI know, I gave you the impression that we would be using linear models and not ANOVAs, but the thing is, ANOVAs have always been based on linear models. In a way ANOVA isn’t a test of its own, not in the way we think of \\(t\\)-tests or \\(\\chi\\)-squared tests. ANOVA is plural, they are a set of tools for pulling comparisons straight out of linear models in the best way. So that’s another great reason for having bothered to understand something of how linear models work.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA and linear models</span>"
    ]
  },
  {
    "objectID": "04-anova.html#one-way-comparisons---groups-in-a-single-variable",
    "href": "04-anova.html#one-way-comparisons---groups-in-a-single-variable",
    "title": "4  ANOVA and linear models",
    "section": "4.2 One-Way comparisons - groups in a single variable",
    "text": "4.2 One-Way comparisons - groups in a single variable\nThe situation where we have just one variable is called a ‘One-Way’ ANOVA.\nNow that we have a solid way of thinking about contrasts as the slope between the categories, we can think of ANOVA as a tool for pulling out the significances in the best way. All we have to do is learn how to specify the contrasts for ANOVA.\nEvery time we do ANOVA we need a model to feed into it. Here’s the most common way ANOVA is done in R, with the aov() and TukeyHSD() functions, you’ve probably seen this before.\n\nano &lt;- aov(model)\nTukeyHSD(ano)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = model)\n\n$group\n            diff        lwr       upr     p adj\ntrt1-ctrl -0.371 -1.0622161 0.3202161 0.3908711\ntrt2-ctrl  0.494 -0.1972161 1.1852161 0.1979960\ntrt2-trt1  0.865  0.1737839 1.5562161 0.0120064\n\n\nIt seems to do the job, though the ‘flavour’ of ANOVA it does is sometimes limited and applies only when the standard assumptions of ANOVA are met.\n\n\n\n\n\n\nNote\n\n\n\nA scary thing that statisticians often say is that such-and-such a method is only applicable when certain assumptions are met. This can make scientists nervy about applying any methods in case it is wrong. I would like to encourage you to relax about this aspect. Most statistical tests are pretty robust to against violations, and if anything tend to get more conservative (IE, generate fewer significant results) in these cases. There are a few assumptions and even a few types of data that we need to be aware of. I dedicate some space in the last chapter to understanding where these trip-ups might happen.\n\n\nA better alternative than the quick and dirty ANOVA approach above (in the sense of flexibility for the user) is the multcomp package function glht() (general linear model hypothesis test), which is more flexible with respect to which designs and contrasts you can get out, at the expense of being a little more complicated. The basic case is straightforward though.\n\nlibrary(multcomp)\ntested &lt;- glht(model, linfct = mcp(group = \"Tukey\"))\nsummary(tested)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = weight ~ group, data = PlantGrowth)\n\nLinear Hypotheses:\n                 Estimate Std. Error t value Pr(&gt;|t|)  \ntrt1 - ctrl == 0  -0.3710     0.2788  -1.331   0.3909  \ntrt2 - ctrl == 0   0.4940     0.2788   1.772   0.1979  \ntrt2 - trt1 == 0   0.8650     0.2788   3.103   0.0122 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nThe linfct option just takes a specification of the things to be tested, and the mcp() function is a helper that generates the comparison based on a text description, here that the variable group should be analysed by ‘Tukey’.\nBy printing the summary we see the contrast hypotheses writ explicitly (e.g. the difference between ctrl and trt1 is 0) and the conclusions: there is no evidence to suggest either treatment is different from the control, but the difference we observe between the trt1 and trt2 occurs by chance only about 1.2 percent of the time, so is deemed ‘significant’.\nAnd that’s it! A properly done and specified use of the linear model and a subsequent ANOVA with Tukey’s post hoc used to determine differences.\nWe’ll see more of how to use glht() as we go.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA and linear models</span>"
    ]
  },
  {
    "objectID": "04-anova.html#two-way-comparisons---groups-in-multiple-variables",
    "href": "04-anova.html#two-way-comparisons---groups-in-multiple-variables",
    "title": "4  ANOVA and linear models",
    "section": "4.3 Two-Way comparisons - groups in multiple variables",
    "text": "4.3 Two-Way comparisons - groups in multiple variables\nOften we’ll have experimental data where we have more than one explanatory variable, for example, compost and fertiliser and want to know the effects of each on a response variable like yield. Where you have two variables, it’s called a Two-Way ANOVA.\nTwo-Way comparisons are pretty similar in practice to One-Way comparisons. So similar in fact that you’re going to jump in and try one, without any further instruction\n\n\n\n\n\n\nFor you to do\n\n\n\n\nUse the function its_compost_time() to load some data on the effects of changing compost type and a supplement on plant size.\nBuild a linear model specifying that size is related to the two other explanatory variables. We haven’t explicitly discussed the syntax for two variables, but in the linear model a extra variables is added with ‘+’, thats how its done in R e.g. lm(y ~ a + b + c). Inspect the model.\nCarry out Tukey’s to test the hypotheses i) that the true difference in means between Formula X1 and X2 is 0, and ii) that the true difference in means between John Innes #1 and #2 is 0.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA and linear models</span>"
    ]
  },
  {
    "objectID": "04-anova.html#interactions-between-variables",
    "href": "04-anova.html#interactions-between-variables",
    "title": "4  ANOVA and linear models",
    "section": "4.4 Interactions between variables",
    "text": "4.4 Interactions between variables\nWorking with multiple variables is complicated over the single case as we have the possibility of an interaction between the variables to consider. That is to say that the response in an experiment may be stronger under conditions a and b than in a or b alone whether a or b alone is greater than a control or not. We can visualise this as straight lines like in the diagrams below.\n\nits_interaction_example_time()\n\n\n\n\n\n\n\n\nWe can see the effect of interaction quite clearly in the two types of data, whenever a & b is used then we have greater responses, either in greater means or in steeper gradients.\nLet’s work through an example that highlights how we identify and investigate this with linear models and ANOVAs. Here’s some data on reported enjoyment of some food, with different condiments added\n\nfood &lt;- its_food_data_time()\n#look at specific rows 1,21,41,61\nfood[c(1,21,41,61),]                                      \n\n             Food Condiment Enjoyment\n1  Tortilla Chips   Hummous  87.19762\n21 Tortilla Chips       Jam  55.72871\n41       Porridge   Hummous  57.22117\n61       Porridge       Jam  91.89820\n\n\nLooking at those in the way we have already - each variable individually - then we would generate the following plots and lines to examine.\n\nits_food_plot_time()\n\n\n\n\n\n\n\n\nWithout rushing ahead to do the modelling, we see that hummous has a slightly greater effect on enjoyment than jam, whereas the enjoyment of the two food types is much more similar. So without a hypothesis test the dangerously thin conclusion would be ‘use hummous to enhance your enjoyment of Porridge or Tortilla Chips’. We might be suspect of this conclusion not only because it seems not to line up with our intuitive sense of what’s going on, but also because of those strange splits in the data. Look within each column and you can see that there is a definite clustering that is not a good sign, we possibly don’t have a good specification of our data here.\nLet’s see what the model says, in specifying the second variable can be added with a + as\n\nmodel_1 &lt;- lm(Enjoyment ~ Food + Condiment, data = food)\nsummary(model_1)\n\n\nCall:\nlm(formula = Enjoyment ~ Food + Condiment, data = food)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-21.593 -15.526  -1.348  14.832  25.822 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         75.3978     3.0674  24.580   &lt;2e-16 ***\nFoodTortilla Chips   0.3384     3.5419   0.096    0.924    \nCondimentJam        -0.9693     3.5419  -0.274    0.785    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.84 on 77 degrees of freedom\nMultiple R-squared:  0.00109,   Adjusted R-squared:  -0.02486 \nF-statistic: 0.04201 on 2 and 77 DF,  p-value: 0.9589\n\n\nThe summary isn’t promising, it looks like neither is significant. Let’s do the ANOVA and get a clearer view.\nThe call to glht() is a bit more complicated than before, but not much\n\nsummary(glht(model_1, linfct = mcp(Food = \"Tukey\", Condiment = \"Tukey\") ) )\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Enjoyment ~ Food + Condiment, data = food)\n\nLinear Hypotheses:\n                                     Estimate Std. Error t value Pr(&gt;|t|)\nFood: Tortilla Chips - Porridge == 0   0.3384     3.5419   0.096    0.994\nCondiment: Jam - Hummous == 0         -0.9693     3.5419  -0.274    0.954\n(Adjusted p values reported -- single-step method)\n\n\nNeither factor seems to be significant. Hmm. This seems like a slightly strange conclusion - and it is. The presence of two variables is confusing this approach. Look at what we get if we split the data by the two variables at once.\n\nits_food_two_ways_time()\n\n\n\n\n\n\n\n\nOk! That’s very different and very much clearer. The enjoyment is very much dependent on the combination of food and condiment. This is a classic case of interaction between variables. You get results that are conditional on the combined values of the variables.\n\n\n\n\n\n\nNote\n\n\n\nThe cross-over of the lines is a visual diagnostic of the presence of an interaction effect.\n\n\n\n4.4.1 Analysing and modelling an interaction effect\nThe interaction effect should be checked for in the linear model. It is quite easy to check for and requires a slight extension to syntax. An interaction term can be specified with the :.\n\ninteraction_model &lt;- lm(Enjoyment ~ Food + Condiment + Food:Condiment, data = food)\n\n(there is also a short hand that allows the whole thing to be specified in one term *, which is used like lm(Enjoyment ~ Food * Condiment, data=food))\nand when we print the summary() we get the book-keeping issue of not all the results we want to see being immediately available, but we can see the usual stuff.\n\nsummary(interaction_model)\n\n\nCall:\nlm(formula = Enjoyment ~ Food + Condiment + Food:Condiment, data = food)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.9463  -2.8645  -0.2551   2.7201  10.8500 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                      60.4259     0.9553   63.25   &lt;2e-16 ***\nFoodTortilla Chips               30.2822     1.3510   22.41   &lt;2e-16 ***\nCondimentJam                     28.9745     1.3510   21.45   &lt;2e-16 ***\nFoodTortilla Chips:CondimentJam -59.8876     1.9106  -31.34   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.272 on 76 degrees of freedom\nMultiple R-squared:  0.9283,    Adjusted R-squared:  0.9254 \nF-statistic: 327.9 on 3 and 76 DF,  p-value: &lt; 2.2e-16\n\n\nThis seems much more like what we expect from the graph, significance everywhere! Basically what the summary is saying is that the Food, Condiment and both together have an effect on the reported enjoyment. This is a bit confusing, because the previous model said that the main effects (Food, Condiment) weren’t significant. The issue is the way the two models separate the data. The point is that in the second model the significance for the main effect is reliant on the interaction, so we can’t generalise to say that Food or Condiment alone has significant effect on enjoyment. We must ignore these main effects in our interpretation.\nBut are the contrasts presented here really all the ones we’re interested in? These seem a bit generic and hard to interpret. This is generally the case so we need to know how to extract the ones we’re interested in.\nIn our linear model way of thinking this means which lines do we want to test for zero slopes? There can be many lines we could imagine depending on how we decide to group the data and the number of variables that we have. Let’s define which we’ll look at before we begin.\nLet’s see whether food alone or condiment alone has an effect. This would be like the first situation we looked at,\n\nits_food_plot_time()\n\n\n\n\n\n\n\n\nin the way that the output we’ve seen so far has it, this would be\n\nPorridge - Tortilla Chips == 0\nHummous - Jam == 0\n\nLet’s also see whether food * condiment has an effect. This would be like the interaction situation.\n\nPorridge:Jam - Tortilla Chips:Jam == 0\nPorridge:Hummous - Tortilla Chips:Hummous == 0\n\n\nits_food_two_ways_time()\n\n\n\n\n\n\n\n\nSo we have four lines of interest to look at - four contrasts.\nFor the two main non-interaction effects we could think to look at these as we’ve done before, using the mcp() function with the interaction_model with the explicit interaction in it, like this\n\nsummary(\n  glht(interaction_model, linfct = mcp(\n    Food = \"Tukey\",\n    Condiment = \"Tukey\"\n  ))\n)\n\nWarning in mcp2matrix(model, linfct = linfct): covariate interactions found --\ndefault contrast might be inappropriate\nWarning in mcp2matrix(model, linfct = linfct): covariate interactions found --\ndefault contrast might be inappropriate\n\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Enjoyment ~ Food + Condiment + Food:Condiment, data = food)\n\nLinear Hypotheses:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \nFood: Tortilla Chips - Porridge == 0   30.282      1.351   22.41   &lt;1e-10 ***\nCondiment: Jam - Hummous == 0          28.974      1.351   21.45   &lt;1e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nThis gives a result, but actually throws up a warning. Since we have an interaction term in our model, we have a complication. The glht() function has spotted that there are interacting terms and potential for confounding and the \\(p\\)-values are therefore a bit suspect without being a bit more careful. We need to take account of the interaction as a term of its own in our hypothesis tests. Annoyingly, this isn’t an easy thing to specify in the glht() function and the easiest way in practice is to just do all the comparisons.\n\n\n\n\n\n\nThe Contrast Matrix\n\n\n\nThe reason that the warnings are thrown in the interaction model is to do with an ANOVA internal object called the Contrasts Matrix, which specifies the contrasts and is used in the linear algebra of the ANOVA and Tukey’s method. The Contrast Matrix is basically a grid with the different samples and contrasts as the rows and columns with a load of ones and zeroes in it. For Tukey’s method to work the Contrast Matrix should be ‘orthogonal’, which roughly means symmetric around a certain axis. When we get the interaction term in the model we lose the orthogonality in the Contrast Matrix and Tukey’s method stops working well. The orthogonality is one of the assumptions that statisticians talk about. It is possible to set up different Contrast Matrices and there are methods for getting significance for non-orthogonal ones, however that does take us a bit too far into theory. For most purposes, except for those with very large numbers of variables it is convenient to use the alternative method below.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA and linear models</span>"
    ]
  },
  {
    "objectID": "04-anova.html#doing-all-pairwise-interactions",
    "href": "04-anova.html#doing-all-pairwise-interactions",
    "title": "4  ANOVA and linear models",
    "section": "4.5 Doing all pairwise interactions",
    "text": "4.5 Doing all pairwise interactions\nAlthough we’re interested in only two specific interactions, usually it’s easier to do all pairwise comparisons in one step, as we don’t often have so many interacting variables that it gets unwieldy. To do this we must add an interaction column to our data and model that. The interaction() function is built for just this reason and allows us to add an interaction column directly from existing data.\n\nfood_2 &lt;- food %&gt;% dplyr::mutate(FoodCondiment = interaction(Food, Condiment))\nknitr::kable( food_2[c(1,21,41,61),] , align = \"c\")\n\n\n\n\n\nFood\nCondiment\nEnjoyment\nFoodCondiment\n\n\n\n\n1\nTortilla Chips\nHummous\n87.19762\nTortilla Chips.Hummous\n\n\n21\nTortilla Chips\nJam\n55.72871\nTortilla Chips.Jam\n\n\n41\nPorridge\nHummous\n57.22117\nPorridge.Hummous\n\n\n61\nPorridge\nJam\n91.89820\nPorridge.Jam\n\n\n\n\n\nWe can see that all we’ve done is add a column that describes the interaction. We can use this in the place of the individual variables as before and now don’t need to explicitly mention the interaction in the specification because it is modelled implicitly in the new column. That means our model looks like this\n\ninteraction_model2 &lt;- lm(Enjoyment ~ FoodCondiment, data = food_2)\n\nTo do the contrasts we can use the single interaction column as the target of Tukey.\n\nsummary(\n  glht(interaction_model2, linfct = mcp(FoodCondiment = \"Tukey\"))\n  )\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Enjoyment ~ FoodCondiment, data = food_2)\n\nLinear Hypotheses:\n                                                 Estimate Std. Error t value\nTortilla Chips.Hummous - Porridge.Hummous == 0     30.282      1.351  22.414\nPorridge.Jam - Porridge.Hummous == 0               28.974      1.351  21.446\nTortilla Chips.Jam - Porridge.Hummous == 0         -0.631      1.351  -0.467\nPorridge.Jam - Tortilla Chips.Hummous == 0         -1.308      1.351  -0.968\nTortilla Chips.Jam - Tortilla Chips.Hummous == 0  -30.913      1.351 -22.881\nTortilla Chips.Jam - Porridge.Jam == 0            -29.605      1.351 -21.913\n                                                 Pr(&gt;|t|)    \nTortilla Chips.Hummous - Porridge.Hummous == 0     &lt;1e-04 ***\nPorridge.Jam - Porridge.Hummous == 0               &lt;1e-04 ***\nTortilla Chips.Jam - Porridge.Hummous == 0          0.966    \nPorridge.Jam - Tortilla Chips.Hummous == 0          0.768    \nTortilla Chips.Jam - Tortilla Chips.Hummous == 0   &lt;1e-04 ***\nTortilla Chips.Jam - Porridge.Jam == 0             &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nWe can see all possible interaction groupings and lines, without any warnings. We can see that the significances make good sense. The Porridge and Jam is no more enjoyable than the Tortilla Chips and Hummous, the Porridge and Hummous is no more enjoyable than the Tortilla Chips and Jam and all the other match and mismatch food and condiments are as we might expect from this very obviously loaded example.\nWe said we wanted to look specifically at the interaction between the Porridge with Jam and Tortilla Chips with Jam - we can see that there is a significant difference in enjoyment, about 29 points. Similarly Porridge with Hummous is less enjoyable than Tortilla Chips with Hummous, by about 30 points.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA and linear models</span>"
    ]
  },
  {
    "objectID": "04-anova.html#summary",
    "href": "04-anova.html#summary",
    "title": "4  ANOVA and linear models",
    "section": "4.6 Summary",
    "text": "4.6 Summary\nWe’ve looked at how to use linear models to think about differences between lots of categories and at what it means for variables to be interacting. We learned that ANOVA is inherently a test based on a linear model that is designed to do all comparisons at once and we learned how to carry the ANOVAs out having built the proper linear model for cases with and without interactions. We know all we need to use R to perform ANOVAs with linear models - which always use linear models anyway.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA and linear models</span>"
    ]
  },
  {
    "objectID": "04-anova.html#extra-credit-anova-model-level-p-and-as-a-hypothesis-test",
    "href": "04-anova.html#extra-credit-anova-model-level-p-and-as-a-hypothesis-test",
    "title": "4  ANOVA and linear models",
    "section": "4.7 Extra Credit: ANOVA model-level \\(p\\) and as a hypothesis test",
    "text": "4.7 Extra Credit: ANOVA model-level \\(p\\) and as a hypothesis test\nRecall that when we introduced linear models we looked at the statistics of the coefficients (the column \\(Pr(&gt;|t|)\\) in the coefficient block of the summary) and the statistics of the whole model, the \\(p\\)-value at the end.\nWhen we did the simple linear model as an alternative of the \\(t\\)-test, then these two \\(p\\)-values were the same - this is because the model then only had one coefficient, so the \\(p\\) of that coefficient was the overall \\(p\\). With more than one coefficient, then the overall model score is made up differently. The overall model can be significant, whereas the individual variables/groups/coefficient within may not be. That’s what we saw when we looked at the PlantGrowth data.\n\nsummary(model)\n\n\nCall:\nlm(formula = weight ~ group, data = PlantGrowth)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.0710 -0.4180 -0.0060  0.2627  1.3690 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5.0320     0.1971  25.527   &lt;2e-16 ***\ngrouptrt1    -0.3710     0.2788  -1.331   0.1944    \ngrouptrt2     0.4940     0.2788   1.772   0.0877 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.6234 on 27 degrees of freedom\nMultiple R-squared:  0.2641,    Adjusted R-squared:  0.2096 \nF-statistic: 4.846 on 2 and 27 DF,  p-value: 0.01591\n\n\nNone of the reported variable/group/coefficient values are significant but the model level \\(p\\) is. This indicates that one of the groups is significant. This is because the ANOVA as a test tests the hypothesis that all lines between groups have slopes of zero. When one line isn’t likely to have a zero slope the model \\(p\\) is low\nIn terms of a formal hypothesis test what we’re asking amounts to an extension to what we saw with the \\(t\\)-test:\n\nAll flat lines with slopes of zero is equivalent to the Null hypothesis\n\n\\(H_{0}\\) the group means are all equal\n\nAt least one \\(p\\)-value that suggests the slope is rare is equivalent to the Alternative hypothesis\n\n\\(H_{1}\\) the group means are not all equal\n\n\nIn other words we can think of the ANOVA testing the idea that all the groups are the result of random sampling from all the observations, if this were true the slopes between groups would all be the same.\nIt’s by using the post-hoc tests like Tukey’s we get at the specific differences between groups.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA and linear models</span>"
    ]
  },
  {
    "objectID": "04-anova.html#extra-credit-testing-specific-interactions",
    "href": "04-anova.html#extra-credit-testing-specific-interactions",
    "title": "4  ANOVA and linear models",
    "section": "4.8 Extra Credit: Testing specific interactions",
    "text": "4.8 Extra Credit: Testing specific interactions\nThe table output is a bit rich and confusing, you can get a simpler output at the expense of some more work. For the two sets of interactions we’re interested in we can look at them specifically but naming them explicitly in glht is trickier than we’ve done so far.\nWe have to specify a matrix of comparisons ourselves. The first step is to work out all the different interactions of the levels of the food*condiment interaction term. We can do that with the interaction() function\n\nf_c_interactions &lt;- interaction(food$Food, food$Condiment, sep=\":\")\nhead(f_c_interactions)\n\n[1] Tortilla Chips:Hummous Tortilla Chips:Hummous Tortilla Chips:Hummous\n[4] Tortilla Chips:Hummous Tortilla Chips:Hummous Tortilla Chips:Hummous\n4 Levels: Porridge:Hummous Tortilla Chips:Hummous ... Tortilla Chips:Jam\n\n\nWe can see that this is just a factor object with all the combinations of Food and Condiment. Using the levels() function gives us all the unique values in the order that R will use them.\n\nlevels(f_c_interactions)\n\n[1] \"Porridge:Hummous\"       \"Tortilla Chips:Hummous\" \"Porridge:Jam\"          \n[4] \"Tortilla Chips:Jam\"    \n\n\nNow we can make the matrix, our eventual matrix will look like this\n\n\n                                          Porridge:Hummous\nPorridge:Jam - Tortilla Chips:Jam                        0\nPorridge:Hummous - Tortilla Chips:Hummous                1\n                                          Tortilla Chips:Hummous Porridge:Jam\nPorridge:Jam - Tortilla Chips:Jam                              0            1\nPorridge:Hummous - Tortilla Chips:Hummous                     -1            0\n                                          Tortilla Chips:Jam\nPorridge:Jam - Tortilla Chips:Jam                         -1\nPorridge:Hummous - Tortilla Chips:Hummous                  0\n\n\nWe can see that there is a row per comparison and a column per possible interaction. At the intersection we write a zero if we don’t want to include that possible interaction in the contrast, a 1 if we want it to be the first part and a -1 if we want it to be the second part (IE, the part after the minus sign).\nAs the levels() function gives us the order, we set up the rows one by one and join them together.\n\nP.J_TC.J &lt;- c(0,0,1,-1)\nP.H_TC.H &lt;- c(1,-1,0,0)\n\nNow we can stick them together, use the levels() function as the column names and add row names. Note you can call the rows what you like, so you dont have to use the long names, but the columns must be named and ordered according to the levels() function\n\ncontr_of_interest &lt;- rbind(P.J_TC.J, P.H_TC.H)\ncolnames(contr_of_interest) &lt;- levels(f_c_interactions)\nrownames(contr_of_interest) &lt;- c(\"P:J - TC:J\",\n          \"P:H - TC:H\")\n\ncontr_of_interest\n\n           Porridge:Hummous Tortilla Chips:Hummous Porridge:Jam\nP:J - TC:J                0                      0            1\nP:H - TC:H                1                     -1            0\n           Tortilla Chips:Jam\nP:J - TC:J                 -1\nP:H - TC:H                  0\n\n\nNow we can do the test using the custom matrix.\n\nsummary(glht( interaction_model, linfct = contr_of_interest))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nFit: lm(formula = Enjoyment ~ Food + Condiment + Food:Condiment, data = food)\n\nLinear Hypotheses:\n                Estimate Std. Error t value Pr(&gt;|t|)    \nP:J - TC:J == 0   88.862      3.021   29.41   &lt;1e-10 ***\nP:H - TC:H == 0   30.144      2.136   14.11   &lt;1e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nAnd there we have the specific interaction contrasts. Note how in doing this we don’t generate any warnings even though we used the model with the explicit interaction term, this is because when we generate our own contrast matrix like this we get an appropriate orthogonality for the test.\n\n\n\n\n\n\nRoundup\n\n\n\n\nWorking with multiple variables goes the same as working with just one\nANOVA is a flexible tool for specifying comparisons between variables in linear models\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor you to do Complete the interactive tutorial online https://tsl-bioinformatics.shinyapps.io/anova/",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>ANOVA and linear models</span>"
    ]
  },
  {
    "objectID": "05-discrete.html",
    "href": "05-discrete.html",
    "title": "5  Non-parametric tests and linear models",
    "section": "",
    "text": "5.1 Common misrepresentations of discrete data\nSo far we’ve looked at tests where the dependent or response measurement has been continuous, that is a measurable number on a continuous scale, like mass or fluorescence. In this section we’ll look at how straight lines can be used to understand differences when we have a discrete or categorical response output. A discrete response variable is one where we have certain categories of result, ‘tall’ or ‘short’, ‘dead’ or ‘alive’ or ‘infected’ or ‘not’. You’ll likely be familiar with these approaches from such things as the chi-squared (\\(\\chi^2\\)) test or other so-called ‘non-parametric’ test like the Mann-Whitney.\nWe’ll start by looking at how these data really are different from the data we’ve used already, common mistakes are always enlightening.\nA common place where analysing discrete data goes wrong is when the analyst confuses the categoric with the continuous, this is often caused by a bad naming scheme as much as a lack of appreciation of the real nature of the data. Often, using numbers as the names for categories can lead the unaware analyst to make a critical mistake. Let’s consider a plant infection assay (sometimes called an HR assay). Here a large-ish leaf of a plant is infected at points on its surface with either different strains or varieties of some pathogen and controls. After a period of incubation the severity of disease at each patch is assessed by eye and a score of disease applied. Sometimes that score will be a numeric one that may be like this example from Supplemental Figure 1 A in a 2020 PNAS paper by Gao et al. Gao et al. (2020)\nIn the figure we can see that a number has been attached to a category, roughly an amount of disease. The numbers increase as disease does but it is a very rough and therefore discontinuous fit. The change in size in numbers don’t relate to each other in the same way that the changes in disease do. The unit difference from 0 to 1 doesn’t seem to be copied in any of the other units and 5 doesnt have just 5 times more apparent disease than 1. The scale has numbers in it, but it isn’t continuous.\nWe can see what the scale represents if we try and use words to express the categories.\nlibrary(itssl)\nits_hr_score_scheme_time()\n\n\n\n\nseverity\nscore\n\n\n\n\nDead\n4\n\n\nVery Ill\n3\n\n\nIll\n2\n\n\nNo Effect\n1\nWhich looks fine at first glance, but again isn’t continuous.\nTypically this will be used in a replicated infection experiment and give data that look like this when collected, which is where the problem arises.\nscores &lt;- its_hr_scores_time()\nscores %&gt;% its_table_time()\n\n\n\n\nstrain\nreplicate\nscore\n\n\n\n\ncontrol\n1\n1\n\n\nmild\n1\n3\n\n\ndeadly\n1\n4\n\n\ncontrol\n2\n2\n\n\nmild\n2\n3\n\n\ndeadly\n2\n4\n\n\ncontrol\n3\n1\n\n\nmild\n3\n3\n\n\ndeadly\n3\n3\nWe now have a table that looks to computers and humans alike as if it is full of numbers, which it isn’t, its full of numbers in the place of words. A simple mental test is to try and use the categories as numbers and see if they behave. For example, is a score of ‘2’ twice that of ‘1’, in this case, is ‘Ill’ twice the effect of ‘No Effect’? Clearly it isn’t, confirming that these numbers aren’t continuous numbers at all, merely place holders for some other conception of the severity of the disease.\nThe problem is exacerbated by not paying attention to this and jumping straight to a plot. Consider this:\nlibrary(ggplot2)\nscores %&gt;% ggplot() + \n  aes(strain, score) + \n  geom_jitter(aes(colour = replicate))\nLooks good?\nNo. By the sweet warmth of the first suns of spring, no.\nThese data are misrepresented by this plot. There are some alarm bells that should ring when we look at this. The first is that scale for replicate. The scale shows replicate values like 1.5 and 2.5 - we didn’t do a replicate 1.5 (not least because it doesn’t make sense to do a replicate .5). So why has ggplot drawn that scale - because it saw numbers and assumed the data in this column are continuous and not discrete. This needs fixing, the replicate is a category, really, not a number. We wouldn’t lose any meaning if we used A,B,C or one,two,three and while the computer is good at recognising text as categories, it just thinks the numbers are real numbers. So we’ll need to avoid doing this, or be prepared to correct it.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-parametric tests and linear models</span>"
    ]
  },
  {
    "objectID": "05-discrete.html#common-misrepresentations-of-discrete-data",
    "href": "05-discrete.html#common-misrepresentations-of-discrete-data",
    "title": "5  Non-parametric tests and linear models",
    "section": "",
    "text": "Note\n\n\n\nBy using numbers for our score, then we have been able to use ‘geom_jitter()’ as a representation and it has generated additions to the scores that leave it with decimal points and that isn’t correct either. It seems defensible on the grounds that if we didn’t use geom_jitter() all the points would be in one place but to avoid the problem we should be doing something very different in the first place.\n\n\n\n5.1.1 Twisting names into numbers confuses the mind\nThe next level of mistake that follows from believing that the scores are numbers is treating them like numbers. We often see the plot evolve in this manner\n\nscores %&gt;% ggplot() + \n  aes(strain, score) + \n  geom_boxplot() + \n  geom_jitter(aes(colour = replicate))\n\n\n\n\n\n\n\n\nWhat the cuss? This is a dreadful misrepresentation of the data!\nThis plot makes us see things that aren’t really there - particularly statistics like means and ranges, and relative magnitude differences between categories.\n\n\n5.1.2 This plot does not mean what I think you think it means\nWell, not you specifically, but someone. Someone definitely thinks what I think they think it means because this overloaded mistake keeps coming up.\nWe think we can see in this plot statistics like means and ranges and infer differences because the boxplot shows them. But the boxplot itself is a dreamlike fabrication. The things it purports to show like the mean of the data, its interquartile range etc are each a numeric feature calculated using formulae based on numbers. But these data are not numbers - they are category names that happen to have digits to represent them. We’ve squeezed numbers in where no numbers should be and invented statistical lies.\nThe use of numbers as names for the categories created a problem of mental overloading - simultaneaously knowing that the data are categorical and treating them as continuous. Believing that because we’ve used numbers for categories we can treat them as numbers. On top of this the presentation tricks our mind into considering the results as if these statistics were real.\n\n\n\n\n\n\nImportant\n\n\n\nIf we use the actual category names we see how ridiculous the boxplot is - consider mean(Ill, No Effect, Ill) = 0.66, it doesn’t make any sense. By using numbers as proxies for our categories, we’ve confused the issue and the knock-on effect is that we start to read (conciously or unconciously) things we shouldn’t from the plot. One unavoidable impression from the plot is that ‘mild’ strain is somehow about 3/4 of the badness of the ‘deadly’ strain. Does that mean the plants were three-quarters dead? Of course not. The misrepresentation in these plots leaves with bad intuition about the relationships in our data.\n\n\nThe use of boxplots to show categories is seductive, it gives an impression of transparency and apparent differences when we use numbers, this is a case where the road to hell is paved with good intentions.\nWith these plots as a base the analysts next move is to run statistical analysis in the way we have learned and, sadly, generate results that are worse than meaningless.\nAnd indeed this does happen in published results, see this figure from the same Gao et al. (2020) paper .\n A barchart with all the errors we mentioned, the bars represent means, the error bars represent standard errors and the legend reports an ANOVA done on these data that concludes a significant reduction in the one low sample.\n\n\n5.1.3 Avoiding these errors by building a strong foundation in our data sets\nWe must avoid these category confusions. There are some key places we can do this in our analysis workflow\n\nKnow and declare the proper data type to R\nUse a statistical test/model type appropriate to the datatype\n\nWhen we load our data into R, we’ll need to make sure that we use the right data types. As a result of this we’ll find that the plots we try to make will come out more appropriately - R will adapt to the data as far as it can. Second, when it comes to doing hypothesis tests we will have to use the proper test for the data type. As we are using the linear model as the basis for our interpretations we’ll need to learn the adaptations to that.\nIn the rest of this chapter we’ll look at correctly describing data to R, creating an appropriate plot for some data and then back to our main thread - using the linear model as a basis for our understanding of statistical tests - this time with categorical response variable.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-parametric tests and linear models</span>"
    ]
  },
  {
    "objectID": "05-discrete.html#setting-type-properly",
    "href": "05-discrete.html#setting-type-properly",
    "title": "5  Non-parametric tests and linear models",
    "section": "5.2 Setting type properly",
    "text": "5.2 Setting type properly\nAt the start of an analysis, when we’re loading data into R is our best opportunity to correct datatype, before we’ve done any work on it and before it starts to get in the way. In a lot of everyday cases we’ll be loading text in from an Excel file or something similar like a .csv or .txt file, so that will be our example case.\n\n\n\n\n\n\nNote\n\n\n\nBase R provides the ‘read.csv()’ (read dot csv) function for us to load ‘.csv’ files and no option for loading Excel files. The tidyverse packages readr and readxl provide the read_csv() and read_excel() (read underscore csv) options respectively. You’ll see read.csv() a lot in older code and quick tutorials, but it is a bit clunky. Some of read.csv()’s default behaviours can be a bit unpredictable and we have to undo some of its work sometimes. So we’ll look at the more consistent tidyverse offerings.\n\n\n\n5.2.1 Setting type with read_csv()\nOn loading data with read_csv(), we get a column specification - this tells us what R thinks each column contained, we must check it carefully to make sure R understands the data as you do. Here we’ll load in the mock HR data we used above.\n\nlibrary(readr)\nread_csv(\"data/sample.csv\")\n\nRows: 9 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): strain\ndbl (2): replicate, score\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 9 × 3\n  strain  replicate score\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 control         1     1\n2 mild            1     3\n3 deadly          1     4\n4 control         2     2\n5 mild            2     3\n6 deadly          2     4\n7 control         3     1\n8 mild            3     3\n9 deadly          3     3\n\n\nSo we can see that R thinks the column strain contains character data (text), and the replicate and strain column data are double (numeric type) data. Well, almost one out of three is pretty bad. Although we (foolishly) coded the categoric replicate and strain as numbers, they aren’t, they’re categories (or factors, in statistic parlance). We can use a column specification in the read_csv() function to force these to be factors.\n\n\n\n\n\n\nNote\n\n\n\nFactors are a statistical name for a categorical variable. Each factor is made up of one or more ‘levels’ the different values that factor can take. In our HR score data, the factor would be ‘score’ and it’s levels would be ‘3’,‘1’,‘2’ and ‘4’. There are lots of tools that work with factors in R, they are a common object.\n\n\nThe col_factor() function tells R that these columns should be a factor when loading.\n\nread_csv(\n  \"data/sample.csv\",\n  col_types = cols(\n    strain = col_factor(NULL),\n    replicate = col_factor(NULL),\n    score = col_factor(NULL)\n  )\n)\n\n# A tibble: 9 × 3\n  strain  replicate score\n  &lt;fct&gt;   &lt;fct&gt;     &lt;fct&gt;\n1 control 1         1    \n2 mild    1         3    \n3 deadly  1         4    \n4 control 2         2    \n5 mild    2         3    \n6 deadly  2         4    \n7 control 3         1    \n8 mild    3         3    \n9 deadly  3         3    \n\n\nThis is much better, R now knows not to treat any of those columns as numbers, so the mistakes we’re trying to avoid are much less likely to happen.\nWe can go one step further and explicitly state the allowed values in a factor. When we do this we get to pick the order that R will deal with them in (and this is important in our data because control &lt; mild &lt; deadly in some sense) and it will spot when we try to load in a factor level that we haven’t declared, which can save us headaches down the road.\n\nscores &lt;- read_csv(\n  \"data/sample.csv\",\n  col_types = cols(\n    strain = col_factor( levels = c(\"control\", \"mild\", \"deadly\")),\n    replicate = col_factor( levels = c(\"1\", \"2\", \"3\")),\n    score = col_factor( levels = c(\"1\", \"2\", \"3\", \"4\"))\n  )\n)\n\nscores\n\n# A tibble: 9 × 3\n  strain  replicate score\n  &lt;fct&gt;   &lt;fct&gt;     &lt;fct&gt;\n1 control 1         1    \n2 mild    1         3    \n3 deadly  1         4    \n4 control 2         2    \n5 mild    2         3    \n6 deadly  2         4    \n7 control 3         1    \n8 mild    3         3    \n9 deadly  3         3    \n\n\nIf you inspect this output and the one previous we can see that we have an order that respects what we told R the data should look like. This is more obvious when we plot as the axes etc will automatically come out in that order.\n\n\n5.2.2 Setting type post hoc with transmute()\nOften our data won’t come straight from a file, it’ll come from some other function that had its own view on the types. To set types with any old dataframe, use transmute() from dplyr()\n\nlibrary(dplyr)\n\nscores %&gt;% transmute(\n  strain = as.factor(strain),\n  replicate = as.factor(replicate),\n  score = as.factor(score)\n)\n\n# A tibble: 9 × 3\n  strain  replicate score\n  &lt;fct&gt;   &lt;fct&gt;     &lt;fct&gt;\n1 control 1         1    \n2 mild    1         3    \n3 deadly  1         4    \n4 control 2         2    \n5 mild    2         3    \n6 deadly  2         4    \n7 control 3         1    \n8 mild    3         3    \n9 deadly  3         3    \n\n\nNote that transmute() will drop any columns you don’t explicitly mention, so any unconverted columns like genuine continuous data should be included in the argument.\n\nscores %&gt;% transmute(\n  strain = as.factor(strain),\n  replicate = as.factor(replicate),\n  score = as.factor(score),\n  some_numeric_col, other_numeric_col\n)",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-parametric tests and linear models</span>"
    ]
  },
  {
    "objectID": "05-discrete.html#plots-with-categoric-x-and-y-axis",
    "href": "05-discrete.html#plots-with-categoric-x-and-y-axis",
    "title": "5  Non-parametric tests and linear models",
    "section": "5.3 Plots with categoric \\(x\\) and \\(y\\) axis",
    "text": "5.3 Plots with categoric \\(x\\) and \\(y\\) axis\nNow we have our data in the right format we can get to plotting, let’s try and repeat the plot we went for when we first looked at these data.\n\nscores %&gt;% ggplot() +\n  aes(strain, score) +\n  geom_jitter(aes(colour = replicate ))\n\n\n\n\n\n\n\n\nBetter but not perfect. We get the replicate labelled properly - as discrete categories rather than a continuous scale, and the strain is in a sensible order. But the jitter still leaves us with the impression that we have numeric data. We can fix this but first let’s jump to repeating our earlier mistake with boxplots\n\nscores %&gt;% ggplot() +\n  aes(strain, score) +\n  geom_boxplot() +\n  geom_jitter(aes(colour = replicate))\n\n\n\n\n\n\n\n\nOK, weird. The boxplot clearly fails, there isn’t the proper data to draw a boxplot, coding our data as factors has saved us this error too. Though not explictly! At least it sends some sort of signal that something isn’t right with our plot.\nMoving on to evolve our plot, lets remove the jitter and go to a geom_point() which puts our points in the exact place, without jitter.\n\nscores %&gt;% ggplot() +\n  aes(strain, score) + \n  geom_point(aes(colour=replicate))\n\n\n\n\n\n\n\n\nthis leaves us with the problem that some of our points are overlapped by others. We need a way to show them without moving them off the spot. We can do that by changing the spot size according to the number of points making it up, geom_count() does that for us.\n\nscores %&gt;% ggplot() +\n  aes(strain, score) + \n  geom_count()\n\n\n\n\n\n\n\n\nAnd with that we can see the number of datum that make up each point. This is a clearer representation of the categoric data than the early attempts and doesn’t lead us to the same poor mental models.\nIt is possible to get a prettier and more descriptive plot with the different replicates side by side and coloured, but it takes a different set of geoms and a slightly involved approach which has more to do with using dplyr and ggplot so we can leave that as an exercise for another time. The point here is that an appropriate plot for categoric data will save us from a poor understanding of the relationships in the data.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-parametric tests and linear models</span>"
    ]
  },
  {
    "objectID": "05-discrete.html#linear-models-and-a-categoric-y-variable",
    "href": "05-discrete.html#linear-models-and-a-categoric-y-variable",
    "title": "5  Non-parametric tests and linear models",
    "section": "5.4 Linear models and a categoric \\(y\\) variable",
    "text": "5.4 Linear models and a categoric \\(y\\) variable\nAfter all that exposition about the difference of categories and plotting them properly, how can we apply our knowledge of linear models to find differences between \\(x\\) categories now that our \\(y\\) is also categoric and not continuous?\nOne thing we haven’t considered up to now with our categories is that, although categories don’t behave like numbers, they can behave like a queue. They often do have an intrinsic and meaningful order. A category like our HR score definitely has an order: \\(score\\ 1 &lt; score\\ 2 &lt; score\\ 3 &lt; score\\ 4\\) even if the intervals are not smooth or equal or defined in any other way. Conversely, some categories don’t have an order, e.g species 1 and species 2 aren’t greater or lesser than each other. We need to treat ordered and unordered categories differently.\n\n5.4.1 Ordered categoric response variables\nThe steps for working with an ordered categoric response variable are as follows\n\nConvert the values observed in the ordered categoric response variable to a rank\nProceed as before\n\nIt’s that easy! Ranks are continuous and work as if they were a continuous scale, so we can use them as we did before. Let’s look at how to rank an ordered categoric variable\nThe first step is to tell R that the factor is in fact an ordered one, and what that order is\n\nobservations &lt;- c(\"none\", \"some\", \"some\", \"none\", \"lots\", \"many\")\n\nordfac_observations &lt;- factor(observations, \n                          levels = c(\"none\", \"some\", \"many\", \"lots\", \"all\"),\n                          ordered = TRUE\n                          )\n\nAll we’ve done here is create some data in observations then turn it into a factor, the levels option sets the allowed levels and the ordered option tells R to take the given order. Let’s inspect the factor object by printing\n\nordfac_observations\n\n[1] none some some none lots many\nLevels: none &lt; some &lt; many &lt; lots &lt; all\n\n\nWe see that R knows the data and the order of the levels. Note that even if a level doesn’t appear in the data, as long as it is declared in levels R still knows about it and it’s place, should it come across it.\nWe can convert to a rank quite easily with the rank() function.\n\nrank(ordfac_observations)\n\n[1] 1.5 3.5 3.5 1.5 6.0 5.0\n\n\nAnd R converts our category to a rank based on the order we provided. Note that ties are broken, so the two nones get equal but split rank, as do the two somes. This operation gives us a numeric scale we can use as if the data were continuous.\n\n\n5.4.2 Making linear models with ranked data\nLet’s calculate the rank score and add it to the score data frame with transmute(), then plot the rank data.\n\nscores &lt;- scores %&gt;% transmute(\n  score = factor(score, levels = c(\"1\",\"2\",\"3\",\"4\"), ordered = TRUE),\n  rank_score = rank(score),\n  strain,replicate\n)\n\nggplot(scores) + aes(strain, rank_score) + geom_jitter(aes(colour = replicate))\n\n\n\n\n\n\n\n\nWe can see the ranks and replicates in the scatter plot that we are used to, we have a similar view as to that we saw with the categoric scatter plot.\nNow we can move on to the modelling and the ANOVA\n\nmodel &lt;- lm(rank_score ~ strain, data = scores)\nsummary(model)\n\n\nCall:\nlm(formula = rank_score ~ strain, data = scores)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n  -2.0   -0.5    0.0    1.0    1.0 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2.0000     0.6455   3.098 0.021160 *  \nstrainmild     3.5000     0.9129   3.834 0.008618 ** \nstraindeadly   5.5000     0.9129   6.025 0.000944 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.118 on 6 degrees of freedom\nMultiple R-squared:  0.8611,    Adjusted R-squared:  0.8148 \nF-statistic:  18.6 on 2 and 6 DF,  p-value: 0.002679\n\nlibrary(multcomp)\nsummary(glht(\n  model, linfct = mcp(strain = \"Tukey\")\n))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = rank_score ~ strain, data = scores)\n\nLinear Hypotheses:\n                      Estimate Std. Error t value Pr(&gt;|t|)   \nmild - control == 0     3.5000     0.9129   3.834  0.02024 * \ndeadly - control == 0   5.5000     0.9129   6.025  0.00215 **\ndeadly - mild == 0      2.0000     0.9129   2.191  0.15143   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nGreat, some clear answers. The strains are likely not the same as the control, but there is no evidence for difference between the strains.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-parametric tests and linear models</span>"
    ]
  },
  {
    "objectID": "05-discrete.html#hypothesis-tests",
    "href": "05-discrete.html#hypothesis-tests",
    "title": "5  Non-parametric tests and linear models",
    "section": "5.5 Hypothesis Tests",
    "text": "5.5 Hypothesis Tests\nAs we mentioned at the start of the chapter there are hypothesis tests that we can use instead of the linear model approach for the ordered categoric response variable case. These are the Mann-Whitney U test (also called the Wilcoxon Signed Rank test) which is for a two group situation (like a \\(t\\)-test) and the Kruskal-Wallis test, which is for a multi-group situation (like the ANOVA).\nHowever, we run into some problems when doing these tests, especially for multiple categories. The Mann-Whitney U only works on two groups, which is a limitation. It is used as below, though first we’ll need to extract the two groups we want. We will do this by filtering but then we’ll need to extract any unused levels in the filtered factor strain with droplevels()\n\nlibrary(dplyr)\ntwo_groups &lt;- filter(scores, strain != \"deadly\") %&gt;% \n  droplevels() %&gt;% \n  transmute(score = as.numeric(as.character(score)),\n            strain, replicate\n            )\n\nstr(two_groups)\n\ntibble [6 × 3] (S3: tbl_df/tbl/data.frame)\n $ score    : num [1:6] 1 3 2 3 1 3\n $ strain   : Factor w/ 2 levels \"control\",\"mild\": 1 2 1 2 1 2\n $ replicate: Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 2 2 3 3\n\nwilcox.test(score ~ strain, data = two_groups)\n\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): cannot\ncompute exact p-value with ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  score by strain\nW = 0, p-value = 0.05935\nalternative hypothesis: true location shift is not equal to 0\n\n\nSo the Mann-Whitney U (Wilcoxon) test tells us that the difference between the scores between the two strains is not likely to be 0. Scaling this up to more than two groups takes a Kruskal-Wallis test\n\nkruskal.test(rank_score ~ strain, data = scores)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  rank_score by strain\nKruskal-Wallis chi-squared = 6.8889, df = 2, p-value = 0.03192\n\n\nNow this is disappointing, as the Kruskal-Wallis test tells us that at least one of the groups is different from the others, but crucially it doesn’t tell us which ones! So we end up doing a multiple wilcox.test() and applying a correction to the \\(p\\)-value. The linear model and ANOVA approach, proves to be a little more straightforward now that we have the knack.\n\n5.5.1 But aren’t the tests just easier?\nAs with the \\(t\\)-test, then in practice, sometimes, yes, these tests are easier. But the same reason for using the linear model applies as with the \\(t\\)-test - it gives us a general framework in which to work and develop a good intuition about the data we are studying and a good conceptual tool with which to think about it. As ever the individual hypothesis tests are just easier. But as we’ve seen they run into limitations of their own.\n\n\n\n\n\n\nRoundup\n\n\n\n\nIt is easy to mistake categories for continuous data when numbers are use as names.\nUsing numbers as names does not make data quantitative\nRanking data makes it possible to analyse ordered categoric data in a linear model\n\n\n\n\n\n\n\n\n\nFor you to do\n\n\n\nComplete the interactive tutorial online https://tsl-bioinformatics.shinyapps.io/type/",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-parametric tests and linear models</span>"
    ]
  },
  {
    "objectID": "05-discrete.html#references",
    "href": "05-discrete.html#references",
    "title": "5  Non-parametric tests and linear models",
    "section": "5.6 References",
    "text": "5.6 References\n\n\n\n\nGao, Chuyun, Huawei Xu, Jie Huang, Biying Sun, Fan Zhang, Zachary Savage, Cian Duggan, et al. 2020. “Pathogen Manipulation of Chloroplast Function Triggers a Light-Dependent Immune Recognition.” Proceedings of the National Academy of Sciences 117 (17): 9613–20. https://doi.org/10.1073/pnas.2002759117.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Non-parametric tests and linear models</span>"
    ]
  },
  {
    "objectID": "06-loglinear.html",
    "href": "06-loglinear.html",
    "title": "6  \\(\\chi ^2\\) tests and linear models",
    "section": "",
    "text": "6.1 The problem with unordered response data\nIn the last chapter we looked at discrete data that was ordered and got around it, as hypothesis tests do, by working on ranked data with a linear model. In this section we’ll look at discrete data that isn’t ordered, or is nominal, things like agree, disagree, don't know, or yellow, green, wrinkled, smooth. We’ll also look at discrete data in the form of counts or frequencies.\nIf we have unordered categoric response data (\\(y\\)-axis) we find ourselves in a bit of a pickle if we want to try to apply a linear model to understand relationships, because there are no numbers at all. In every other example we’ve looked at the \\(y\\) response data has been numeric or at least coercible into numbers.\nWe’ll put ourselves in the shoes of Gregor Mendel and work through his monohybrid cross experiment on flower colour. Mendel’s first step would have been to work out the flower colours after a cross with different coloured true breeding parents, leaving him with a raw dataframe like this:\nlibrary(itssl)\nits_mendel_data_time()\n\n# A tibble: 600 × 2\n   cross result\n   &lt;chr&gt; &lt;chr&gt; \n 1 WP    P     \n 2 WP    P     \n 3 WP    P     \n 4 PW    P     \n 5 WP    P     \n 6 PW    P     \n 7 PW    P     \n 8 PW    P     \n 9 WP    P     \n10 PP    P     \n# ℹ 590 more rows\nWhich isn’t very helpful at this stage, how on earth do we get two columns of text into a linear model? Persevering, Mendel would’ve gone on to count the numbers of each colour.\nits_mendel_count_data_time()\n\n# A tibble: 2 × 2\n  colour count\n  &lt;chr&gt;  &lt;int&gt;\n1 P        459\n2 W        141\nMendel famously went on to calculate the ratios, or relative frequencies of each.\nits_mendel_frequency_time()\n\n# A tibble: 1 × 6\n      P     W ratio_p ratio_w freq_p freq_w\n  &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1   459   141    3.26       1  0.765  0.235\nBut that doesn’t get us any nearer. The problem is that we have just got count (or frequency) data and nothing else. It seems that it isn’t far from the ordered data case, we can imagine plotting the data as we did with HR score, but the response variable is colour and there’s no clear explanatory (\\(x\\)) variable, so what would go on that axis? Perhaps the colour of the parents in the cross as categories would do? There isn’t an order to this so we can’t meaningfully apply the rank to create a proxy for order. We can’t look at slopes again because there’s no sense in the order of the response variable. In short it’s a mess.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>$\\chi ^2$ tests and linear models</span>"
    ]
  },
  {
    "objectID": "06-loglinear.html#the-problem-with-unordered-response-data",
    "href": "06-loglinear.html#the-problem-with-unordered-response-data",
    "title": "6  \\(\\chi ^2\\) tests and linear models",
    "section": "",
    "text": "Huh?\n\n\n\nWhy isn’t colour an explanatory variable? And why can’t then frequency or count be the \\(y\\)-axis? Well, at a push they sort of might nearly be. But maybe not really. Remember the values of an explanatory variable should be something we can change as an experimenter, they are the values that we change deliberately to see what the effect on the response is. Even in our categoric \\(x\\)-experiments we know what the values will be beforehand. Here, arguably we didn’t, crosses happened and phenotypes popped out, so it’s a bit muddier. If we do use that approach we end up with lots of observations condensed into one number as a further issue.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>$\\chi ^2$ tests and linear models</span>"
    ]
  },
  {
    "objectID": "06-loglinear.html#we-have-to-compare-models-not-groups.",
    "href": "06-loglinear.html#we-have-to-compare-models-not-groups.",
    "title": "6  \\(\\chi ^2\\) tests and linear models",
    "section": "6.2 We have to compare models, not groups.",
    "text": "6.2 We have to compare models, not groups.\nIt is possible to do this sort of comparison with linear models, but it gets to be fiddly and involved because we need to apply a mathematical transformation to our counts and to work on the likelihood ratio of the response to stick to some assumptions of the modelling process.\nBriefly we go from this linear model, with interaction terms\ny ~ a + b + c + a:b\nTo two models with logs all over them, one with interaction terms, one without\nlog(yi) ~ log(N) + log(ai) + log(bi) + log(ci) + log(aibi)\nlog(yi) ~ log(N) + log(ai) + log(bi) + log(ci)\nAnd then we have to compare the models to see which fit the data best.\nWhich is more complicated than we want to get into and ultimately the process is not worth it in most cases, because there are alternatives. Pragmatically, the answer is to use the \\(\\chi^2\\) and related tests in this case.\nIt is worthwhile to remember that to analyse unordered categoric response data we need to compare models, because that means assessing which model ‘fit’ the data we have best. This is a useful way to think about what the tests like the \\(\\chi^2\\) and Fisher’s Exact test are doing. They compare the observed counts - being considered one full set of data (or one model), against the expected counts from some ideal or some category split, a second model.\nThe log-linear model and the tests give closely equivalent results in most cases.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>$\\chi ^2$ tests and linear models</span>"
    ]
  },
  {
    "objectID": "06-loglinear.html#the-chi2-test",
    "href": "06-loglinear.html#the-chi2-test",
    "title": "6  \\(\\chi ^2\\) tests and linear models",
    "section": "6.3 The \\(\\chi^2\\) test",
    "text": "6.3 The \\(\\chi^2\\) test\nIn the \\(\\chi^2\\) test we ask ‘does one set of counts differ from another?’. This might be a hypothetical ‘expected’ set of counts for the response of interest compared to some standard. For example, in genetics data we might ask whether the observed ratio of phenotypes matches an expected 9:3:3:1. More generally, we might ask whether the counts in one subset of categories matches another, so in a survey to ask whether respondents agree that broccoli is a nice food, with response ‘agree, disagree, don’t know’, we might compare responses between adults and children.\nThe Null Model here in this case is not the Normal distribution that we used for everything else in our linear models but a statistical distribution called the \\(\\chi^2\\) distribution. Although it is a different distribution we use it in pretty much the same way, as a tool to give us an idea of how things would behave in a situation with no differences. Again we’re just asking how likely the differences we see would be if there was really no difference.\nThe basic calculation in the \\(\\chi^2\\) test is the difference between observed and expected numbers in each category subset. In Mendel’s data this would be the difference between the observed number of “P” and “W”, from the expected number - given we did 600 plants, then for a \\(3:1\\) we’d expect 450 “P” and 150 “W”. This difference is then compared to values of the \\(\\chi^2\\) distribution and returns a \\(p\\)-value that represents how far away from the mean the difference is. If it is an extreme value (in the tails) the \\(p\\)-value is lower.\nThe hypotheses are set as follows:\n\n\\(H_{0}\\) the observed counts show no evidence that they are different from the expected counts\n\\(H_{1}\\) the observed counts would not occur often by chance\n\n\n6.3.1 Performing the test\nTo do the test for the simplest case - Mendel’s flower data, we need to get a dataframe with the observed counts on one row and the expected counts on another.\n\nobserved_counts &lt;- its_mendel_count_data_time() %&gt;% \n  tidyr::pivot_wider(names_from = c(\"colour\"), values_from = c(\"count\") )\nobserved_counts\n\n# A tibble: 1 × 2\n      P     W\n  &lt;int&gt; &lt;int&gt;\n1   459   141\n\n\nWe then need to make the equivalent row for the expected counts - recall we had 600 plants, so calculate the expected number of “P” and “W”\n\nexpected_counts &lt;- tibble::tibble(\n   P = 600 * 3/4,\n   W =  600 * 1/4\n)\nexpected_counts\n\n# A tibble: 1 × 2\n      P     W\n  &lt;dbl&gt; &lt;dbl&gt;\n1   450   150\n\n\nWe then need to stick those rows together\n\nchi_sq_input &lt;- dplyr::bind_rows(observed_counts, expected_counts)\nrownames(chi_sq_input) &lt;- c(\"observed\", \"expected\")\n\nWarning: Setting row names on a tibble is deprecated.\n\nchi_sq_input\n\n# A tibble: 2 × 2\n      P     W\n* &lt;dbl&gt; &lt;dbl&gt;\n1   459   141\n2   450   150\n\n\nFinally we can do the test with the function chisq.test()\n\nchisq.test(chi_sq_input)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  chi_sq_input\nX-squared = 0.29034, df = 1, p-value = 0.59\n\n\nThe test shows us that the \\(p\\)-value of the \\(\\chi^2\\) test is greater than 0.05 so we conclude that there is no evidence that the observed number of each flower colour differs from the expected and that we do indeed have a \\(3:1\\) ratio. Note that the test automatically does the necessary correction for small sample sizes if the data need it.\n\n\n6.3.2 More than one variable\nThe data we had above only had one variable, flower colour. What if we have multiple categoric variables to compare? Largely, the process is the same but making the table is more difficult.\nConsider this data frame of voting intentions between generations\n\nvoting_data &lt;- its_voting_data_time()\nvoting_data\n\n  generation alignment count\n1     boomer   fascist   279\n2  millenial   fascist   165\n3     boomer instagram    74\n4  millenial instagram    47\n5     boomer   marxist   225\n6  millenial   marxist   191\n\n\nThis time we have two variables, with two or three levels of each. To make the contingency table for chisq.test() we can use xtabs() which takes an R formula as a description of how to make the table. Luckily, these are exactly the same formula we used to make linear models.\n\ntabulated &lt;- xtabs(count ~ ., data = voting_data)\ntabulated\n\n           alignment\ngeneration  fascist instagram marxist\n  boomer        279        74     225\n  millenial     165        47     191\n\n\nHere we make a formula that says count is the output variable, and . are the independent or row and column variables (. in formula like this just means everything else). The table comes out as we expect and we can go on to do the chisq.test() as before on the new table.\n\nchisq.test(tabulated)\n\n\n    Pearson's Chi-squared test\n\ndata:  tabulated\nX-squared = 7.0811, df = 2, p-value = 0.029\n\n\nHere the \\(p\\) value tells us that the pattern of voting intention is significant, but the numbers are hard to interpret … do millenials vote less for instagram than boomers? We can make things easier to interpret if we have a proportion table. The function prop.table() can make one of those.\n\nprop.table(tabulated, margin = 1)\n\n           alignment\ngeneration    fascist instagram   marxist\n  boomer    0.4826990 0.1280277 0.3892734\n  millenial 0.4094293 0.1166253 0.4739454\n\n\nThe margin option takes a 1 if we want proportions across the rows, 2 if we want proportions down the columns. We can see that the difference between the two generations comes largely from a swing from fascist to marxist.\n\n\n6.3.3 More than one pairwise comparison\nIf we have more than two levels in our comparison category (that is, a larger contingency table than 2 x 2), we run into a problem. Look at these data\n\njob_mood &lt;- its_job_mood_time()\n\n\ntab &lt;- xtabs(Freq ~., data = job_mood)\ntab\n\n           role\nmood        carpenter cooper milliner\n  curious          70      0      100\n  tense            32     30       30\n  whimsical       120    142      110\n\n\nwe have data on the reported mood of people in different jobs. Note that there are three levels of each of the categoric variables. We can make the table and can go straight to the \\(\\chi^2\\) test.\n\ntab &lt;- xtabs(Freq ~., data = job_mood)\ntab\n\n           role\nmood        carpenter cooper milliner\n  curious          70      0      100\n  tense            32     30       30\n  whimsical       120    142      110\n\nchisq.test(tab)\n\n\n    Pearson's Chi-squared test\n\ndata:  tab\nX-squared = 93.67, df = 4, p-value &lt; 2.2e-16\n\n\nUmm, it’s significant. But weren’t we expecting to see significances between groups? As with the ANOVA it’s done the overall result. We need to do a post-hoc operation to do the full set of pairwise comparisons. The package rcompanion has a nice function for this, pairwiseNominalIndependence(), we set the option method to decide which correction for multiple comparisons to do, fdr is a good choice.\n\nlibrary(rcompanion)\npairwiseNominalIndependence(tab, method = \"fdr\")\n\n           Comparison p.Fisher p.adj.Fisher  p.Gtest p.adj.Gtest  p.Chisq\n1     curious : tense 8.97e-16     1.35e-15 2.22e-16    3.33e-16 1.07e-14\n2 curious : whimsical 8.98e-29     2.69e-28 0.00e+00    0.00e+00 5.47e-21\n3   tense : whimsical 5.98e-01     5.98e-01 6.07e-01    6.07e-01 6.11e-01\n  p.adj.Chisq\n1    1.60e-14\n2    1.64e-20\n3    6.11e-01\n\n\nBetter. But not quite! The groups compared are the different moods, presumably we wanted to look at the differences between the different roles. The table is in the wrong orientation in that case.\nWe can explicitly state the orientation of the table by manipulating the formula in xtabs(). Compare the results of these two calls\n\nxtabs(Freq ~ role + mood, data = job_mood)\n\n           mood\nrole        curious tense whimsical\n  carpenter      70    32       120\n  cooper          0    30       142\n  milliner      100    30       110\n\nxtabs(Freq ~ mood + role, data = job_mood)\n\n           role\nmood        carpenter cooper milliner\n  curious          70      0      100\n  tense            32     30       30\n  whimsical       120    142      110\n\n\nWe usually want the form with the variable we’re comparing in the rows, that’s the Freq ~ role + mood. We can then do the pairwise \\(\\chi^2\\).\n\ntab &lt;- xtabs(Freq ~ role + mood, data = job_mood)\npairwiseNominalIndependence(tab, method = \"fdr\")\n\n            Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest  p.Chisq\n1   carpenter : cooper 5.26e-20     7.89e-20  0.0000      0.0000 3.38e-15\n2 carpenter : milliner 7.81e-02     7.81e-02  0.0773      0.0773 7.81e-02\n3    cooper : milliner 1.66e-28     4.98e-28  0.0000      0.0000 1.89e-21\n  p.adj.Chisq\n1    5.07e-15\n2    7.81e-02\n3    5.67e-21\n\n\nAnd we can now clearly see the \\(p\\)-values across all the group comparisons. The default output is actually from a range of \\(\\chi^2\\) related tests. In this case always take the p.adj value as the final \\(p\\)-value.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>$\\chi ^2$ tests and linear models</span>"
    ]
  },
  {
    "objectID": "06-loglinear.html#summary",
    "href": "06-loglinear.html#summary",
    "title": "6  \\(\\chi ^2\\) tests and linear models",
    "section": "6.4 Summary",
    "text": "6.4 Summary\nWe’ve finally seen a situation where the linear model paradigm for thinking about statistical tests and hypothesis lets us down, the categorical \\(x\\) and \\(y\\) axis gets just a bit too complicated for the lines idea to remain intuitive, so here we must abandon it. But the alternative hypothesis tests in the \\(\\chi^2\\) family are still available and we’ve learned some useful and general ways to apply those.",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>$\\chi ^2$ tests and linear models</span>"
    ]
  },
  {
    "objectID": "06-loglinear.html#plot-ideas-for-categoric-and-count-data",
    "href": "06-loglinear.html#plot-ideas-for-categoric-and-count-data",
    "title": "6  \\(\\chi ^2\\) tests and linear models",
    "section": "6.5 Plot ideas for categoric and count data",
    "text": "6.5 Plot ideas for categoric and count data\nIn previous chapters we’ve seen how to plot the data we’ve been working on and usually the sort of plot we want has been quite obvious. With the unordered categoric only data we have here, it isn’t so obvious. Often just the table will do! But if you would like some plots here are some rough examples to build from.\n\n6.5.1 Balloon plot\n\nlibrary(ggplot2)\nggplot(job_mood) + aes(mood, role) + geom_point(aes(size = Freq))\n\n\n\n\n\n\n\n\nThis plot shows circles whose size is proportional to the count at each combination.\n\n\n6.5.2 Heatmap\n\nggplot(job_mood) + aes(mood, role) + geom_tile(aes(fill=Freq))\n\n\n\n\n\n\n\n\nThis plot shows tiles whose filled colour represents the count at each combination\n\n\n6.5.3 Stacked bar\n\nggplot(job_mood) + aes(role, Freq) + geom_col(aes(fill = mood))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRoundup\n\n\n\n\nCategoric explanatory (\\(x\\)) and response (\\(y\\)) variables are not amenable to use in linear models\nIn practice we are usually better off using the hypothesis tests\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nComplete the interactive tutorial online https://tsl-bioinformatics.shinyapps.io/chisq/",
    "crumbs": [
      "Common statistical tests",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>$\\chi ^2$ tests and linear models</span>"
    ]
  },
  {
    "objectID": "07-testing_model.html",
    "href": "07-testing_model.html",
    "title": "7  Checking the quality of a linear model",
    "section": "",
    "text": "7.1 Assessing a linear model\nIn this section we’ll look at assessing whether a linear model is a good one, from a model fit point of view. If it is a poor fit then the conclusions we’re trying to make are much less likely to be valid and our science will suffer.\nA decent line fit to the data is essential for good statistical analysis with a linear model. The quality of fit to a linear model can be used to assess whether the data are appropriate for a particular test, even if we intend to just use the test. If we don’t get a reliable fit we don’t get a result we can be confident in from either the linear model and crucially, neither would we if we did the corresponding tests, like the \\(t\\)-test and ANOVA. Let’s examine some model fits.",
    "crumbs": [
      "More applications of linear models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Checking the quality of a linear model</span>"
    ]
  },
  {
    "objectID": "07-testing_model.html#assessing-a-linear-model",
    "href": "07-testing_model.html#assessing-a-linear-model",
    "title": "7  Checking the quality of a linear model",
    "section": "",
    "text": "7.1.1 The terror of normality\nScientists that have done at least a little statistics often seem concerned that their data must be normally distributed for an analysis to be valid. This may stem from reviewers who will ask whether ‘the test is appropriate for the sort of data analysed’ or related ‘whether the distribution of the data is normal’. These questions are sometimes legitimate, thankfully they are easy to answer and you should ask them of your data when you build your model because the answers will help you understand the goodness of your model. The good news is that you don’t need to worry about your data being a super typical normal distribution, instead you can check whether the data are normal enough. All the tests and linear models will be very robust and even tend toward conservatism in their results if the data are all of the below:\n\nrepresented well by their mean\nhave a normal pattern in the residual\nshow a reasonable correlation in a qq-plot\n\n\n\n7.1.2 Checking whether the mean is a good summary\nThe first thing to check, whether you intend to do a simple \\(t\\)-test or a multi-way ANOVA is whether the mean is actually a good summary of the whole of the data. If you have multiple variables you’ll need to check the means of each one. A mean is a good summary of a set of data if it sits nicely in the middle and there are no other peaks or skew in a histogram of that data. This is easier to think about if we draw some pictures. In this set of panels of histograms with density plots the mean (the vertical line) is an increasingly poor summary of the data as we go from left to right along the panels.\n\nlibrary(itssl)\nits_is_the_mean_a_good_summary_time(1000, type = \"hist\")\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\nℹ The deprecated feature was likely used in the itssl package.\n  Please report the issue to the authors.\n\n\n\n\n\n\n\n\n\nThe first one, a normal distribution is summarised well by the mean. The second a normal distribution with a very wide standard deviation is less good. They have the mean at the peak, with the rest of the data falling evenly away. The third, the uniform distribution (in which all outcomes are equally likely) has no peak because the central outcome isn’t more likely than the others though the mean is in the middle so it still has some value. The final two are badly summarised by the mean, the skew-normal distribution has the mean away from the peak because of the long tail and the multimodal has more than one peak. The take-home here is that the model fit and assumptions are increasingly poor as we move along, not that the tests and models become completely useless. In practice our conclusions must become more circumspect and a single test is less convincing, the final two are really quite likely to be difficult to conclude from using normal based linear models..\n\n\n\n\n\n\nFor you to do\n\n\n\nUse the its_is_the_mean_a_good_summary_time() to examine the effect of sample size on how these data look and view them in different plot type\n\n\n\n\n7.1.3 Spotting a good fit to the data\nAnother thing you can do to assess your linear model is check out the residuals. Remember we described these as the distance between the actual data and the fitted line. The distribution of these tells us a lot. Let’s think about these two data sets,\nclose_fit &lt;- its_random_xy_time(20)\nfar_fit &lt;- data.frame(\n  x &lt;- runif(20, 5, 15),\n  y &lt;- runif(20, 5, 15)\n)\n\nits_plot_xy_time(close_fit, line = TRUE)\nits_plot_xy_time(far_fit, line = TRUE)\n\n\n\n\n\n\n\n\n\n\nWe can see the first has a fairly good slope and the points are all relatively close to the line, while in the second the slope is weak because the points are further away. The lm() function calculates the residuals and we can plot them.\nclose_fit_model &lt;- lm(y ~ x, data = close_fit)\nfar_fit_model &lt;- lm(y ~ x, data = far_fit)\n\nplot(close_fit_model, which = 1)\nplot(far_fit_model, which = 1)\n\n\n\n\n\n\n\n\n\n\nHere we see the \\(x\\)-axis value is the value from the model, so the \\(x\\)-axis value of a data point, the \\(y\\)-axis value is the residual itself the distance between the line \\(y\\) value and the observed \\(y\\) value. The first plot shows a nice even scatter and flat line and a range of -2 to 2. The second shows a more erratic scatter with the red line having a little wobble and a much higher range, from - 6 to 4.\nTogether they show us that the second model doesn’t fit as the data as closely as the first, the increased residual size and the more wobbly line mean it isn’t as good. Its still not useless though, a wobbly line is still sometimes useable, we would be more worried if we had these data, which have some hidden structure in. Here’s a non-linear data set and its residual plot\nnon_linear_data &lt;- tibble::tibble(\n  x = 1:20,\n  y = (x ^ 2 ) + runif(20, 3, 60)\n)\n\nits_plot_xy_time(non_linear_data, line = TRUE)\nnon_linear_model &lt;- lm(y ~ x, data = non_linear_data)\nplot(non_linear_model, which = 1)\n\n\n\n\n\n\n\n\n\n\nInitially, the line seems to fit the data quite well, but the giveaway is in the residual plot, which has quite the pattern!! The data are actually a \\(y = x^2\\) relationship with some noise added. By viewing the \\(x\\) vs \\(y\\) plot we don’t easily see that relationship, but the residuals very definitely show that the linear model doesn’t fit the data well, the structure in the residual plot indicates that the model is failing to capture some part of our data. As you might imagine, linear models (and related tests) performed with non-linear data will not give good results.\n\n\n7.1.4 Checking qq-plots for a normal distribution\nThe qq-plot tests the question of whether data are normally distributed directly. Here the \\(x\\) values are basically random numbers drawn from a normal distribution with mean and standard deviation the same as the model data and the \\(y\\) values are the real data. This is easy to do with ggplot()\nlibrary(ggplot2)\nggplot(close_fit) + aes(sample = y) + stat_qq() + stat_qq_line()\nggplot(far_fit) + aes(sample = y) + stat_qq() + stat_qq_line()\nggplot(non_linear_data) + aes(sample = y) + stat_qq() + stat_qq_line()\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese often deviate at the ends of the scatter plot, but the centre parts should fall along the line with random deviation. Here, with these particular data sets, the close_fit and far_fit appear to be matching marginally better overall than the non_linear which is veering around the line quite a lot.\nand again, we can also do this with the residual data which should also be normally distributed, here the lm() function does a lot of the work for us.\nplot(close_fit_model, which = 2)\nplot(far_fit_model, which = 2)\nplot(non_linear_model, which = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRoundup\n\n\n\n\nLinear models work best when the residuals are normally distributed, but linear models are somewhat robust to deviation from this ```",
    "crumbs": [
      "More applications of linear models",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Checking the quality of a linear model</span>"
    ]
  },
  {
    "objectID": "08-predictions.html",
    "href": "08-predictions.html",
    "title": "8  Predictions",
    "section": "",
    "text": "Questions\n\n\nHow can I use the model to make predictions?\n\n\nObjectives\n\n\nLearn how to make predictions from a model\n\n\nKeypoints\n\n\nModels can be used to make new hypotheses\n\nSometimes we will want to use our existing data to build hypotheses to generate new ideas and experiments. The linear model can aid this by using it as a tool to predict what the model outputs would be given a particular set of inputs across the variables that we used to build our model. In this section we’ll take a look at doing things like predicting new data on our response (\\(y\\)-axis) given some \\(x\\) values.\n\n8.0.1 Intuition on prediction from continuous variables\nThe intuition behind this is more straightforward than you might initially think, consider the straight lines from our first section. We had a continuous \\(x\\) and \\(y\\) axis\n\nlibrary(itssl)\ndf &lt;- its_random_xy_time(20)\nits_plot_xy_time(df, line = TRUE)\n\n\n\n\n\n\n\n\nWe can peek into \\(x\\) to see what values we actually used\n\nsort(df$x)\n\n [1]  5.824327  5.895516  7.105123  7.179086  7.375033  7.855269  7.912222\n [8]  8.319600  8.729459  8.852362  9.532381 10.989182 11.510336 12.167571\n[15] 12.329553 12.551050 12.883979 13.216811 13.431172 13.521335\n\n\nAlthough we don’t have a real \\(x = 10\\) in our data, imagine asking the question “what \\(y\\) would we get for \\(x = 10\\)?”. We can intuitively tell what the \\(y\\)-value would be simply by reading off the line at \\(x = 10\\), which is about 20 or from the formula, \\(y = (1.9555 * 10) + 0.7780 = 20.33\\). This is the intuition behind how a linear model prediction works with continuous \\(x\\) and \\(y\\) - we’re just reading off the line.\nIf we build the model, we can ask it to work this out for us directly using the predict() function. predict() takes the model and the new values to be predicted in a data.frame.\n\nmodel &lt;- lm(y ~ x, data = df)\npredict(model, newdata = data.frame(x = c(10)))\n\n       1 \n20.33266 \n\n\nWe see that we get the same value (given a little rounding error).\nWhat happens when we give the predict() function a value we did have data for? Let’s pull out whatever the fifth value of our data was and look at that\n\ndf$x[5]\n\n[1] 12.88398\n\ndf$y[5]\n\n[1] 24.32715\n\n\nThis shows us that the \\(x\\) axis value of 12.88 had the corresponding \\(y\\) value of 24.33. Now let’s use the model to predict the \\(y\\) from the \\(x\\)\n\nvals_to_predict &lt;- data.frame(x = c(df$x[5]))\npredict(model, newdata = vals_to_predict)\n\n       1 \n25.97217 \n\n\nThe result from the model is quite different from the actual observed data value! This isn’t an error. Its because we’re asking the model to predict using the ‘line’ it came up with. Note that this is because the prediction comes from the model which takes into account the whole data. This is the process of ‘best fitting’ which ensures the ‘line’ matches all the points as well as possible, but doesn’t guarantee matching any particular point well.\n\n\n\n\n\n\nNote\n\n\n\nIt is possible to over-complicate models to make them fit all the points by allowing them to take extra parameters and become curves. Adding complexity in this way usually leads to bad models that only fit one particular data set well and is called ‘overfitting’.\n\n\n\n8.0.1.1 Prediction intervals\nIf you are going to predict a value, you might want instead an interval in which that prediction might lie with certain amount of certainty. Like a confidence interval for the position of the mean in a sample, a prediction interval is a range that we are most certain a prediction will land in. This interval takes in the range of spread in the data we build the linear model with and turns it into something useless. Once the model is built, it’s easy to use the predict() function to get the prediction interval\n\nvals_to_predict &lt;- data.frame( x = c(10) )\npredict(model, newdata = vals_to_predict, interval = \"predict\")\n\n       fit      lwr      upr\n1 20.33266 17.52743 23.13788\n\n\nwe can see the predicted value and the lower and upper bounds of the prediction interval.\n\n\n\n8.0.2 Intuition on prediction with categoric variables\nIn the same way we looked at the line to get an intuitive understanding of how the linear model makes predictions, we can look at the groups in a categorical variable to see how \\(y\\) values are predicted from factors.\nConsider the chickwts data.\n\nits_plot_chickwts_time()\n\n\n\n\n\n\n\n\nWe can see that in this data set there is a single categorical variable called feed which is the type of food the chick was raised on, and the resulting continuous output variable of weight. If we model that and do a prediction we can get an intuition on what the prediction() means for each category.\n\nmodel &lt;- lm(weight ~ feed, data = chickwts)\npredict(model,newdata = data.frame(feed = c(\"casein\")))\n\n       1 \n323.5833 \n\npredict(model,newdata = data.frame(feed = c(\"sunflower\")))\n\n       1 \n328.9167 \n\n\nNote that this time we have to use the a level of a factor, because that was the only term in this model. It doesn’t make sense to give it a number. The model returns the fitted value of weight for the level of the factor.\nDo the numbers returned remind you of anything? Aren’t they awfully close to where we expect the mean of each group to be. Let’s check that out by doing a prediction for each feed and comparing with the group mean.\n\n#first get a vector of the chickwts feed names\nfeeds &lt;- sort(unique(chickwts$feed))\n#do the prediction\npreds &lt;- predict(model,newdata = data.frame(feed = feeds) )\n#add the names for clarity\nnames(preds) &lt;-  feeds\n\npreds\n\n   casein horsebean   linseed  meatmeal   soybean sunflower \n 323.5833  160.2000  218.7500  276.9091  246.4286  328.9167 \n\n\nNow calculating the mean from the data.\n\nlibrary(dplyr)\ngroup_by(chickwts, feed) %&gt;% \n  summarize(mean = mean(weight)) \n\n# A tibble: 6 × 2\n  feed       mean\n  &lt;fct&gt;     &lt;dbl&gt;\n1 casein     324.\n2 horsebean  160.\n3 linseed    219.\n4 meatmeal   277.\n5 soybean    246.\n6 sunflower  329.\n\n\nYep, they’re the same. This gives us the intuition that for the model of categoric data the prediction for each group in the category is the centre of it. It may not always be the exact mean, but it’s a useful way of thinking about it.\n\n\n8.0.3 Using predictions in more complicated models\nA significant use of predictions is when we have a mixture of variables that we can’t easily just see the mean for and want to know what the model thinks of those. This is especially useful for hypothesis generation or finding out possible parameter ranges for new experiments. As the last thing we’ll do with predictions we’ll look at the txhousing data, a data set about housing in Texas. This data has a mixture of continuous and categoric variables. We’ll see that this it isn’t more complicated than prediction for a single variable but does give us a much more convenient and powerful way to predict an outcome from provided values.\nFirst a quick look at txhousing (it lives in ggplot2)\n\nlibrary(ggplot2)\nstr(txhousing)\n\ntibble [8,602 × 9] (S3: tbl_df/tbl/data.frame)\n $ city     : chr [1:8602] \"Abilene\" \"Abilene\" \"Abilene\" \"Abilene\" ...\n $ year     : int [1:8602] 2000 2000 2000 2000 2000 2000 2000 2000 2000 2000 ...\n $ month    : int [1:8602] 1 2 3 4 5 6 7 8 9 10 ...\n $ sales    : num [1:8602] 72 98 130 98 141 156 152 131 104 101 ...\n $ volume   : num [1:8602] 5380000 6505000 9285000 9730000 10590000 ...\n $ median   : num [1:8602] 71400 58700 58100 68600 67300 66900 73500 75000 64500 59300 ...\n $ listings : num [1:8602] 701 746 784 785 794 780 742 765 771 764 ...\n $ inventory: num [1:8602] 6.3 6.6 6.8 6.9 6.8 6.6 6.2 6.4 6.5 6.6 ...\n $ date     : num [1:8602] 2000 2000 2000 2000 2000 ...\n\n\nNow let’s build a linear model of property sale price predicted by the city it is in and the year and month of sale.\n\nmodel &lt;- lm(median ~ city + year + month, data = txhousing)\n\nAnd finally get a prediction for a particular case.\n\npredict(model, newdata = data.frame(city = c(\"Abilene\"), year = c(2000), month = c(2)))\n\n      1 \n65392.3 \n\n\nThis shows how the linear model can be used to make predictions and hypothesis for further work.\n\n\n\n\n\n\nNote\n\n\n\n\nModels can be used to make new hypotheses",
    "crumbs": [
      "More applications of linear models",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Predictions</span>"
    ]
  },
  {
    "objectID": "09-glms.html",
    "href": "09-glms.html",
    "title": "9  Generalized Linear Models",
    "section": "",
    "text": "Questions\n\n\nWhat can I use when linear models don’t work well?\n\n\nObjectives\n\n\nKnow that the linear model idea can be extended for more than the Normal Distribution\n\n\nKeypoints\n\n\nLinear models are one member of a larger family of models for many types of data\n\nIn this section we’ll briefly discuss the next level of linear model, the generalised linear model.\nGeneralized Linear Models (GLMs) are, as the name might suggest, a generalization of the linear model that can be used when the residuals are not normally distributed. We went to quite a lot of trouble in this chapter to learn how to identify normally distributed residuals and input data and to press home the idea that if we do have data that look mostly normal then the linear model is still a useful tool. However, there are many situations where your data isn’t going to be anything like normal and that’s where a GLM is helpful. GLMs are particularly useful instance in non-linear situations like exponentially changing data or count data, indeed in earlier chapters we did see some data that definitely didn’t fit a normal (though we didn’t point it out explicitly at the time) the frequency data in the \\(\\chi^2\\) test section wasn’t usable in a linear model without a great deal of fiddling.\n\n\n\n\n\n\nNote\n\n\n\nActually, with a lot of non-normal data, e.g exponential data, we can ‘hack’ our data to be more normal by applying a transformation such as taking logs, and then proceed as before. Often we can’t or shouldn’t and that’s where Generalized Linear Models come in.\n\n\nGLMs can be thought of as clever linear models that you can specify the type of distribution the residual has, this means the mathematics is a lot more complicated, but in practice it’s just another function in R - glm() which is related to lm() and works much like it with some extra options to set.\nGLMs are a powerful thing and great to know about, and once you’ve got the hang of linear models not terribly hard to use, keep them in mind as you work through your analyses and if you come across a data set that doesn’t seem to fit well with linear models, maybe you need to move over to a GLM.\n\n\n\n\n\n\nRoundup\n\n\n\n\nLinear models are one member of a larger family of models for many types of data, Generalized Linear models are the general class of tool.",
    "crumbs": [
      "Beyond linear models",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "prerequisites.html",
    "href": "prerequisites.html",
    "title": "Appendix A — Installing what you need",
    "section": "",
    "text": "A.1 Prerequisites\nThe primary purpose of this course is to help you to understand how to use statistics that will help with your research. The course will try to explain statistics using the same path through the topic that statistics students are educated along, but without the rigorous mathematical background necessary for those students. Instead this course will focus on making you aware of the major concepts and help you to be a better user of statistics in your research.\nStatistics is a computationally heavy topic, so we’ll be making use of the R statistical programming environment to do that side of the work. The rest of this chapter will help you get that set up on your own computer.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Installing what you need</span>"
    ]
  },
  {
    "objectID": "prerequisites.html#prerequisites",
    "href": "prerequisites.html#prerequisites",
    "title": "Appendix A — Installing what you need",
    "section": "",
    "text": "A.1.1 Knowledge prerequisites\nThere are no specific knowledge prerequisites for this book but it will help if you have heard of some common statistical tests, like t, ANOVA and regression. It’ll also be helpful for following some of the code examples if you are familiar with basic R use.\n\n\nA.1.2 Software prerequisites\nYou need to install the following stuff for this book:\n\nR\nRStudio\nSome R packages: devtools and itssl",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Installing what you need</span>"
    ]
  },
  {
    "objectID": "prerequisites.html#installing-r",
    "href": "prerequisites.html#installing-r",
    "title": "Appendix A — Installing what you need",
    "section": "A.2 Installing R",
    "text": "A.2 Installing R\nFollow this link and install the right version for your operating system https://www.stats.bris.ac.uk/R/",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Installing what you need</span>"
    ]
  },
  {
    "objectID": "prerequisites.html#installing-rstudio",
    "href": "prerequisites.html#installing-rstudio",
    "title": "Appendix A — Installing what you need",
    "section": "A.3 Installing RStudio",
    "text": "A.3 Installing RStudio\nFollow this link and install the right version for your operating system https://www.rstudio.com/products/rstudio/download/",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Installing what you need</span>"
    ]
  },
  {
    "objectID": "prerequisites.html#installing-r-packages-in-rstudio.",
    "href": "prerequisites.html#installing-r-packages-in-rstudio.",
    "title": "Appendix A — Installing what you need",
    "section": "A.4 Installing R packages in RStudio.",
    "text": "A.4 Installing R packages in RStudio.\n\nA.4.1 Standard packages - devtools\ndevtools is a standard R package and can be installed like any other you may have done from CRAN. Start RStudio and use the Packages tab in lower right panel. Click the install button (top left of the panel) and enter the package name, then click install as in this picture\n\n\n\nInstalling Packages\n\n\n\n\nA.4.2 Development packages - itssl\nitssl is a new package that contains all the materials including the exercises for this handbook. As it is a development package you need to install it using devtools.\n\nIn the Console tab in the lower left panel of RStudio type devtools::install_github(\"danmaclean/itssl\")\n\nYou may get asked to install newer versions of packages, select 1. All for these questions.\nYou may get asked whether you wish to install the newest version from source, decline this option and install binaries by selecting the appropriate option",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Installing what you need</span>"
    ]
  },
  {
    "objectID": "prerequisites.html#using-the-itssl-package",
    "href": "prerequisites.html#using-the-itssl-package",
    "title": "Appendix A — Installing what you need",
    "section": "A.5 Using the itssl package",
    "text": "A.5 Using the itssl package\nitssl is a package developed solely to accompany this course. Once it is installed you can load it as usual - library(itssl)\nAll the functions in itssl follow this naming scheme its_&lt;something-something&gt;_time() so you’ll be able to spot them as you read along. The main purpose of the functions is to make the course easier to follow and stop us from getting bogged down in a lot of circumstantial code that isn’t directly related to our current point, which will usually be statistical rather than related to programming, hence you’ll be able to get a lot out of this course even if you haven’t used much R before.\nIf you do have a desire to see the code inside the itssl functions it is available at https://github.com/danmaclean/itssl/tree/master/R",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Installing what you need</span>"
    ]
  },
  {
    "objectID": "r-fundamentals.html",
    "href": "r-fundamentals.html",
    "title": "Appendix B — R Fundamentals",
    "section": "",
    "text": "B.1 About this chapter",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "r-fundamentals.html#about-this-chapter",
    "href": "r-fundamentals.html#about-this-chapter",
    "title": "Appendix B — R Fundamentals",
    "section": "",
    "text": "Questions:\n\n\nHow do I use R?\n\n\nObjectives:\n\n\nBecome familiar with R syntax\nUnderstand the concepts of objects and assignment\nGet exposed to a few functions\n\n\nKeypoints:\n\n\nR’s capabilities are provided by functions\nR users call functions and get results",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "r-fundamentals.html#working-with-r",
    "href": "r-fundamentals.html#working-with-r",
    "title": "Appendix B — R Fundamentals",
    "section": "B.2 Working with R",
    "text": "B.2 Working with R\nIn this workshop we’ll use R in the extremely useful RStudio software. For the most part we’ll work interactively, meaning we’ll type stuff straight into the R console in RStudio (Usually this is a window on the left or lower left) and get our results there too (usually in the console or in a window on the right).\nPanels like the ones below mimic the interaction with R and first show the thing to type into R, and below the calculated result from R.\nLet’s look at how R works by using it for it’s most basic job - as a calculator:\n\n 3 + 5\n\n[1] 8\n\n\n\n 12 * 2\n\n[1] 24\n\n\n\n 1 / 3\n\n[1] 0.3333333\n\n\n\n 12 * 2\n\n[1] 24\n\n\nFairly straightforward, we type in the expression and we get a result. That’s how this whole book will work, you type the stuff in, and get answers out. It’ll be easiest to learn if you go ahead and copy the examples one by one. Try to resist the urge to use copy and paste. Typing longhand really encourages you to look at what you’re entering.\nAs far as the R output itself goes, it’s really straightforward - its just the answer with a [1] stuck on the front. This [1] tells us how many items through the output we are. Often R will return long lists of numbers and it can be helpful to have this extra information.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "r-fundamentals.html#variables",
    "href": "r-fundamentals.html#variables",
    "title": "Appendix B — R Fundamentals",
    "section": "B.3 Variables",
    "text": "B.3 Variables\nWe can save the output of operations for later use by giving it a name using the assignment symbol &lt;-. Read this symbol as ‘gets’, so x &lt;- 5 reads as ‘x gets 5’. These names are called variables, because the value they are associated with can change.\nLet’s give five a name, x then refer to the value 5 by it’s name. We can then use the name in place of the value. In the jargon of computing we say we are assigning a value to a variable.\n\n x &lt;- 5\n x\n\n[1] 5\n\n\n\n x * 2\n\n[1] 10\n\n\n\ny &lt;- 3\nx * y\n\n[1] 15\n\n\nThis is of course of limited value with just numbers but is of great value when we have large datasets, as the whole thing can be referred to by the variable.\n\nB.3.1 Using objects and functions\nAt the top level, R is a simple language with two types of thing: functions and objects. As a user you will use functions to do stuff, and get back objects as an answer. Functions are easy to spot, they are a name followed by a pair of brackets. A function like mean() is the function for calculating a mean. The options (or arguments) for the function go inside the brackets:\n\nsqrt(16)\n\n[1] 4\n\n\nOften the result from a function will be more complicated than a simple number object, often it will be a vector (simple list), like from the rnorm() function that returns lists of random numbers\n\nrnorm(100)\n\n  [1]  0.732897757  1.284273849  0.187198869 -1.034243713 -1.210191653\n  [6]  0.529005627  0.032822162 -1.041973338  0.132966823 -0.386635961\n [11] -0.876308020 -0.752281620 -1.173259454  1.244074285  1.866598190\n [16] -1.439940403  0.782396610  2.041652158  2.760626130 -1.748177099\n [21]  0.780466701 -0.650389746  1.344092097  0.979555598  0.665452952\n [26]  2.084609817  1.060719505  0.921245533  0.623392552 -0.438508369\n [31]  0.003045055  0.482742819 -1.625884666  1.416898225  0.049944672\n [36] -1.531147498 -0.466551548 -2.230926776 -0.754107702  1.144560128\n [41] -1.030213004 -0.590831923 -0.972011803 -0.591506929  0.624087089\n [46] -1.033646117  0.426749985  0.424718471 -0.103223218 -0.735826413\n [51] -0.229487406  0.758234802  0.793415736 -0.806586054  0.192014961\n [56]  0.107816854 -0.397479709  0.163718459  0.681293212  0.386425816\n [61]  1.204251194 -0.930337719 -0.077239893  1.591728587  2.111400651\n [66] -0.443678564 -0.214883181  1.068760404  1.829147961 -1.342124997\n [71]  1.133437552 -1.694725778  0.632609984  0.178828164 -0.279367088\n [76]  0.170304240  1.379341712 -1.576169828  1.298837278  3.000938683\n [81] -0.407578563  0.885600067 -0.356960246 -1.086019919 -0.212972813\n [86]  1.567942310 -1.468809170  0.046291557 -0.172891095 -0.489953624\n [91]  0.400655882 -0.709094024  1.285519686  0.847435324 -1.554517576\n [96] -1.418347252 -2.019989059 -0.160130496 -1.083778151 -0.200162877\n\n\nWe can combine objects, variables and functions to do more complex stuff in R, here’s how we get the mean of 100 random numbers.\n\nnumbers &lt;- rnorm(100)\nmean(numbers)\n\n[1] -0.01382273\n\n\nHere we created a vector object with rnorm(100) and assigned it to the variable numbers. We than used the mean() function, passing it the variable numbers. The mean() function returned the mean of the hundred random numbers.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "r-fundamentals.html#dataframes",
    "href": "r-fundamentals.html#dataframes",
    "title": "Appendix B — R Fundamentals",
    "section": "B.4 Dataframes",
    "text": "B.4 Dataframes\nOne of the more common objects that R uses is a dataframe. The dataframe is a rectangular table-like object that contains data, think of it like a spreadsheet tab. Like the spreadsheet, the dataframe has rows and columns, the columns have names and the different columns can have different types of data in. Here’s a little one\n\n\n  names age    score\n1 Guido  24 14.82414\n2 Marty  45 18.67472\n3  Alan  11 82.38981\n\n\nUsually we get a dataframe by loading in data from an external source or as a result from functions, occasionally we’ll want to hand make one, which can be done with various functions, data.frame being the most common.\n\ndata.frame(\n  names = c(\"Guido\", \"Marty\", \"Alan\"),\n  age = c(24,45,11),\n  score = runif(3) * 100\n)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "r-fundamentals.html#packages",
    "href": "r-fundamentals.html#packages",
    "title": "Appendix B — R Fundamentals",
    "section": "B.5 Packages",
    "text": "B.5 Packages\nMany of the tools we use in will come in R packages, little nuggets of code that group related functions together. Installing new packages can be done using the Packages pane of RStudio or the install.packages() function. When we wish to use that code we use the library() function\n\nlibrary(somepackage)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "r-fundamentals.html#using-r-help",
    "href": "r-fundamentals.html#using-r-help",
    "title": "Appendix B — R Fundamentals",
    "section": "B.6 Using R Help",
    "text": "B.6 Using R Help\nR provides a command, called ? that will display the documentation for functions. For example ?mean will display the help for the mean() function.\n\n?mean\n\nAs in all programming languages the internal documentation in R is written with some assumption that the reader is familiar with the language. This can be a pain when you are starting out as the help will seem a bit obscure at times. Don’t worry about this, usually the Examples section will give you a good idea of how to use the function and as your experience grows then the more things will make more sense.\n\n\n\n\n\n\nRoundup\n\n\n\n* R is an excellent and powerful statistical computing environment\n\n\n\n\n\n\n\n\nFor you to do\n\n\n\nComplete the interactive tutorial online https://danmaclean.shinyapps.io/r-start",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>R Fundamentals</span>"
    ]
  },
  {
    "objectID": "acknowledgements.html",
    "href": "acknowledgements.html",
    "title": "Acknowledgements",
    "section": "",
    "text": "This handbook would not have been possible without helpful inspiration from these web pages and leaders in statistical education, please check out their sites.\n\nDanielle Navarro - Learning Statistics with R\nJim Frost - Statistics By Jim\nJonas Kristoffer Linedlov",
    "crumbs": [
      "Appendices",
      "Acknowledgements"
    ]
  }
]